{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJY7QD40vrm-"
   },
   "source": [
    "# Exercise Sheet 1.0 - Text Processing with Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJYUWq73vsk2"
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "The motivation of this exercise is to gain familiarity with the Python programming language. We are going to do some basic text processing and analysis on a plaintext corpus. If you are not with familiar Python or Jupyter notebooks, it is recommended to start with the Python Tutorial notebook before attempting this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLuuYUPQrvNk"
   },
   "source": [
    "## Exercise 0\n",
    "\n",
    "For this exercise, we are going to count the 25 most frequent words in **Alice’s Adventures in Wonderland** by Lewis Carroll. You are free to use any other piece of text of your choice for this exercise. This notebook contains step by step instructions (with some hints) and you are required to fill in the code blocks based on the material covered in the Python Tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T48PL4payl55"
   },
   "source": [
    "### 0. Download the text file.\n",
    "Run the cell below to download the book **Alice’s Adventures in Wonderland** as a text file from [Project Gutenberg](http://www.gutenberg.org), and save into a file called `alice.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1662577029607,
     "user": {
      "displayName": "Oksana Dereza",
      "userId": "05783666325227241892"
     },
     "user_tz": -60
    },
    "id": "nW1cmwsAfXh9",
    "outputId": "99f6d5c8-2049-4035-d133-23adc7a895d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  170k  100  170k    0     0   122k      0  0:00:01  0:00:01 --:--:--  122k\n"
     ]
    }
   ],
   "source": [
    "!curl https://www.gutenberg.org/files/11/11-0.txt > alice.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSRMWLlFfp22"
   },
   "source": [
    "---\n",
    "### 1. Read text from file.\n",
    "Open the text file `alice.txt` and read all the lines into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "QOshGZfAfhA1"
   },
   "outputs": [],
   "source": [
    "lines = open(\"alice.txt\", \"r\", encoding= \"utf-8\").readlines()  # read lines from sherlock.txt into this list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHWe4GdSoOAd"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdF0W047oQ3T"
   },
   "source": [
    "The `open()` function can be used to read the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt9qAKiVhH2m"
   },
   "source": [
    "---\n",
    "### 2. Filter out the metadata.\n",
    "The text file contains some metadata about the book which is not relevant for our analysis. Discard this information by removing the first 54 lines from the beginning and the last 356 lines from the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YwnNTTxUhFkE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'THE END \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[54: -356]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B99yzJaJom24"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTTB9bIVools"
   },
   "source": [
    "Use index slicing to select the required lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTvlIw-whuwy"
   },
   "source": [
    "---\n",
    "### 3. Remove leading and trailing spaces from each line in the list.\n",
    "Each line contains a newline character `\\n` at the end while some lines also contain leading and trailing spaces. This formatting is done for presentation purposes and not relevant for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "UYdh18lHgsj0"
   },
   "outputs": [],
   "source": [
    "clean_lines = []  # store the lines in this list after removing the leading and trailing spaces\n",
    "\n",
    "for line in lines:\n",
    "    clean_lines.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40T7EUhKo3uI"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBfWbLUho5Sn"
   },
   "source": [
    "The `strip()` function can be used to remove leading and trailing spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSu406W9iqMo"
   },
   "source": [
    "---\n",
    "### 4. Remove empty lines from the list.\n",
    "After removing the newline character `\\n` from each line in the list, some strings are now empty and can be discarded safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-1djnrvHh2kc"
   },
   "outputs": [],
   "source": [
    "non_empty_lines = []  # store non empty lines in this list\n",
    "# your code goes here\n",
    "for line in clean_lines:\n",
    "    if line != '':\n",
    "        non_empty_lines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTrgIRNmpQZA"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wj2Oc7vpRuc"
   },
   "source": [
    "An empty string in Python is represented by `''` or `\"\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNCnBgL-jNe1"
   },
   "source": [
    "---\n",
    "### 5. Join all the non empty lines into a single string.\n",
    "Now that we have cleaned the corpus by removing some editorial details and formatting, we can focus on the actual text. Create a single string which contains all the lines from the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "iED8UQpciCv7"
   },
   "outputs": [],
   "source": [
    "text = ' '.join(non_empty_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CddBuKbqLOP"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ib-zeFqsqOMP"
   },
   "source": [
    "The `join` function can be used to join a list of strings into a single string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxri7Uw_keFd"
   },
   "source": [
    "---\n",
    "### 6. Convert to lowercase\n",
    "To keep the word counts consistent, we are going to covert everything lowercase. If we don't do this, the words `the`, `The` and `THE` would be considered distinct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dy8tLkbqj2mw"
   },
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNzM9uEXtPgV"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6xMhrqptRXH"
   },
   "source": [
    "Use the `lower()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6jvhDdJki-_"
   },
   "source": [
    "---\n",
    "### 7. Get a list of all the words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "lyYdI8rrkfLL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'had',\n",
       " 'no',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversations',\n",
       " 'in',\n",
       " 'it,',\n",
       " '“and',\n",
       " 'what']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split()\n",
    "words[40:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZnNKX62tdHS"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN_R11-stel4"
   },
   "source": [
    "The `split()` can be used to get a list of words from a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAcWJvFdVIZZ"
   },
   "source": [
    "### 8. Remove punctuation\n",
    "\n",
    "For a machine, character sequences `rabbit`, `rabbit,` and `rabbit!` are diferrent words, although we as humans understand that this is the same word with/without punctuation marks after it. To avoid this confusion, we can remove punctuation, because it is unnecessary for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'had',\n",
       " 'no',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversations',\n",
       " 'in',\n",
       " 'it',\n",
       " 'and',\n",
       " 'what']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct = '.,?!:;—\"«»()[]{}–~*@#$^&\\/„“‘’-|+=`'\n",
    "new_words = [w.strip(punct) for w in words]\n",
    "\n",
    "new_words[40:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4QPTgQgVRLl"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OSMVZSQVRLn"
   },
   "source": [
    "Use `strip()` function. List comprehensions may also come in handy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ID09CxSky1g"
   },
   "source": [
    "---\n",
    "### 9. How many total words are there in the text?\n",
    "\n",
    "Individuals elements in a text (usually words, but not only) are called **tokens** in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "r8UY3Em8kpRb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26441"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ge6sfS-tnDd"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5LyHU0ktnzG"
   },
   "source": [
    "This can be found by finding the length of the `words` list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ome93kmzk2tU"
   },
   "source": [
    "---\n",
    "### 10. How many unique words are there in the text?\n",
    "\n",
    "Unique words are also called **types** in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "C2rJYlgekqkL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3505"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(new_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmflXPVBt975"
   },
   "source": [
    "#### Hint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7zPnamct-1-"
   },
   "source": [
    "The `set` data type can be used to find unique values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnSpE4-elByQ"
   },
   "source": [
    "---\n",
    "### 11. What are the 25 most frequent words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "V62gHcL1ufqK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1629),\n",
       " ('and', 843),\n",
       " ('to', 715),\n",
       " ('a', 626),\n",
       " ('she', 534),\n",
       " ('of', 505),\n",
       " ('it', 477),\n",
       " ('said', 456),\n",
       " ('alice', 383),\n",
       " ('i', 380),\n",
       " ('in', 360),\n",
       " ('was', 347),\n",
       " ('you', 329),\n",
       " ('as', 262),\n",
       " ('her', 246),\n",
       " ('that', 240),\n",
       " ('at', 208),\n",
       " ('on', 183),\n",
       " ('had', 177),\n",
       " ('with', 176),\n",
       " ('all', 169),\n",
       " ('but', 164),\n",
       " ('for', 149),\n",
       " ('so', 145),\n",
       " ('be', 139)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code goes here (this can be done in less than 10 lines of code)\n",
    "word_count = dict()\n",
    "\n",
    "for word in new_words:\n",
    "    if word in word_count:\n",
    "        word_count[word] += 1\n",
    "    else:\n",
    "        word_count[word] = 1\n",
    "word_count = list(word_count.items())        \n",
    "sorted(word_count, key = lambda x: x[1], reverse = True)[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUH1GqY3uMCe"
   },
   "source": [
    "#### Hints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IokOGFi-uOm1"
   },
   "source": [
    "1. Use a dictionary to store count of each word.\n",
    "2. Convert the dictionary into a list of tuples and sort by counts in descending order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I8RGDU2uj6V"
   },
   "source": [
    "#### Alternate Solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWuhpqKsvNOg"
   },
   "source": [
    "1. Python >= 3.6 supports ordered dictionaries, so there is no need to convert to a list of tuples before sorting.\n",
    "2. Look up the `Counter` container in the `collections` module in the [Python docs](https://docs.python.org/3/library/collections.html#collections.Counter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1604),\n",
       " ('and', 765),\n",
       " ('to', 706),\n",
       " ('a', 614),\n",
       " ('she', 518),\n",
       " ('of', 493),\n",
       " ('said', 420),\n",
       " ('it', 362),\n",
       " ('in', 349),\n",
       " ('was', 328),\n",
       " ('you', 257),\n",
       " ('as', 249),\n",
       " ('i', 249),\n",
       " ('alice', 221),\n",
       " ('that', 216),\n",
       " ('her', 207),\n",
       " ('at', 204),\n",
       " ('had', 176),\n",
       " ('with', 170),\n",
       " ('all', 154),\n",
       " ('on', 142),\n",
       " ('be', 138),\n",
       " ('for', 135),\n",
       " ('very', 126),\n",
       " ('so', 126)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(words)\n",
    "word_counts.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CHWe4GdSoOAd",
    "B99yzJaJom24",
    "40T7EUhKo3uI",
    "lTrgIRNmpQZA",
    "5CddBuKbqLOP",
    "yNzM9uEXtPgV",
    "PZnNKX62tdHS",
    "6Ge6sfS-tnDd",
    "pmflXPVBt975",
    "uUH1GqY3uMCe",
    "6I8RGDU2uj6V"
   ],
   "provenance": [
    {
     "file_id": "1gRsqg-Y-vS3p6Ls8v7Hd17sQlMio2fW3",
     "timestamp": 1600613803292
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
