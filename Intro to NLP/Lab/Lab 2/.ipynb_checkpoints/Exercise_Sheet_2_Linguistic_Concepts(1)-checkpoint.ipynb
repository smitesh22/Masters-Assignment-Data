{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RA4X4gQDsFRR"
   },
   "source": [
    "# Exercise Sheet 2 - Linguistic Concepts\n",
    "## Learning Objectives\n",
    "\n",
    "In this sheet we are going to:\n",
    "- learn more about linguistic structure, analysis and data\n",
    "- do a few exercises on basic linguistic concepts\n",
    "- study some functions in `nltk` for linguistic analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "znjXtNyOtXp3"
   },
   "source": [
    "---\n",
    "# Pen & Paper Exercises\n",
    "# 1. Morphology\n",
    "\n",
    "See lecture slides 16-17.\n",
    "\n",
    "1. What is the stem in the following words: *amusing*, *amusement*, and *amused*.\n",
    "2. What is the lemma in the following words: *amusing*, *amusement*, and *amused*.\n",
    "3. Name two applications that might use these morphological processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OvRcvqEtXp2"
   },
   "source": [
    "---\n",
    "# 2. Syntax\n",
    "## 2.1. Part-of-Speech Tagging\n",
    "Use the POS tag set from the slides to annotate each word in the following sentence with the correct part of speech (see lecture slides 29-30):\n",
    "\n",
    "> *He had an expensive, but very good lunch at the Thai restaurant with the big windows that is opposite the church.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJ6xaZCqjU-z"
   },
   "source": [
    "---\n",
    "## 2.2. Context-free Grammars\n",
    "Define a context-free grammar with production rules for terminal and non-terminal symbols that can be used to analyse/generate the following sentence (see lecture slides 34-35):\n",
    "\n",
    "> *He had lunch at the restaurant.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymSIg3EbtXp0"
   },
   "source": [
    "---\n",
    "## 2.3. Constituency Parsing\n",
    "Draw the phrase structure for the sentence in **1.** (see lecture slides 35-36)\n",
    "\n",
    "> *He had lunch at the restaurant.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owWlA60KtXp1"
   },
   "source": [
    "---\n",
    "### 2.3.1. Recursive Grammar and Phrase Structure\n",
    "Define the grammar rules and draw the phrase structure for the following sentence (see lecture slide 37-38):\n",
    "\n",
    "> *He had lunch at the restaurant on the corner of the street.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVitSnSVtXp4"
   },
   "source": [
    "---\n",
    "## 2.4. Dependency Parsing\n",
    "\n",
    "Draw the dependency structure for the following sentence:\n",
    "\n",
    "> *We ate at a cheap restaurant on the corner of the street.*\n",
    "\n",
    "See lecture slides 40-41 and the Universal Dependencies website for the [list of relations](https://universaldependencies.org/u/dep/) and [annotation guidelines](https://universaldependencies.org/u/overview/syntax.html). You can also encounter another dependency annotation scheme, [Stanford dependencies](https://nlp.stanford.edu/software/dependencies_manual.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XaflKvaYtXp5"
   },
   "source": [
    "---\n",
    "# NLTK\n",
    "Now we will look at some functions in `nltk` for morphological processing of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rJp5KzfEtXp6"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', \"omw-1.4\", 'averaged_perceptron_tagger', 'universal_tagset' ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOYnTrx6tXp7"
   },
   "source": [
    "---\n",
    "## 3. Tokenization\n",
    "\n",
    "Tokenization is the process of dividing a text into smaller units i.e. tokens. \n",
    "\n",
    "`nltk` provides a `word_tokenize` function to tokenize a sentence in a given language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3k_ONfatXp7"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"Galway has a year-round mild, moist, temperate and changeable climate, due to \\\n",
    "the prevailing winds of the North Atlantic Current together with the Gulf Stream.\"\n",
    "\n",
    "tokens = word_tokenize(sentence, language='english')\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxfz9OiitXp9"
   },
   "source": [
    "`nltk` has many pre-defined tokenizers and you can also create your own. More details about the `tokenize` submodule are available [here](https://www.nltk.org/api/nltk.tokenize.html). \n",
    "\n",
    "The default tokenizer uses two classes, [PunktSentenceTokenizer](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.punkt.PunktSentenceTokenizer) and [TreebankWordTokenizer](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.treebank.TreebankWordTokenizer) for the tokenization of a document into sentences and words respectively.\n",
    "\n",
    "You can also call `dir` on any Python module to see what attributes (classes and functions) are defined inside it. Uncomment the following the cell to see the attributes in the `tokenize` subpackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIeij8jctXp9"
   },
   "outputs": [],
   "source": [
    "dir(nltk.tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCNTpUnstXp9"
   },
   "source": [
    "Run the following cell to see the details about the `WhitespaceTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtc9Y-eTtXp9"
   },
   "outputs": [],
   "source": [
    "?nltk.tokenize.WhitespaceTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FXWpgXktXp9"
   },
   "source": [
    "Run the following cell to tokenize the same sentence using the `WhitespaceTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gG8CYnIttXp-"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "tokenizer.tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oybiCjGptXp_"
   },
   "source": [
    "Do you notice any differences here compared to the default tokenizer?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGh1m6J6tXp_"
   },
   "source": [
    "Certain types of texts require special considerations for tokenization. For example, hashtags, mentions and emoji in tweets.\n",
    "\n",
    "Tokenize the following tweet using the default tokenizer and TweetTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7l6sEvXtXp_"
   },
   "outputs": [],
   "source": [
    "tweet = '''Dr @OmniaHZayed gives us a smashing overview of #SemanticAnalysis Information Extraction she elucidates how it all work & what are the likely challenges. #wordsensedisambiguation \n",
    "#homonymy \n",
    "#parsing \n",
    "#semanticrolelabelling \n",
    "#NLP'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ced4yq-ttXp_"
   },
   "outputs": [],
   "source": [
    "# tokenize using the default tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ok6JbbGjtXqA"
   },
   "outputs": [],
   "source": [
    "# tokenize using TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsNhwCaXtXqA"
   },
   "source": [
    "---\n",
    "# 4. Stemming\n",
    "Stemming is a simplified analysis of  word structure by removing endings/beginnings of words - leaving a common stem. There are many algorithms to perform stemming, with [PorterStemmer](https://www.nltk.org/_modules/nltk/stem/porter.html#PorterStemmer) being one of the most widely used. Run the following cell to see the output from the stemmer for the sentence defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QDfJxJvDtXqB"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "for token in tokens:\n",
    "    print(stemmer.stem(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdAVupYRtXqC"
   },
   "source": [
    "---\n",
    "# 5. Lemmatization\n",
    "Lemmatisation is the linguistic analysis of  word structure by a transformation of morphologically related words to a common lemma. \n",
    "\n",
    "Lemmatization is more complex than stemming as it depends on correctly identifying part of speech and meaning of a word in a sentence. Run the following cell to see the output from the [WordNetLemmatizer](https://www.nltk.org/api/nltk.stem.html#nltk.stem.wordnet.WordNetLemmatizer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1AzKSZ7tXqE"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for token in tokens:\n",
    "    print(lemmatizer.lemmatize(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpDdFxsRtXqF"
   },
   "source": [
    "# 6. Part-of-Speech Tagging\n",
    "\n",
    "Finally, `nltk` provides a `pos_tag` function to annotate a sentence using an *off-the-shelf* tagger which uses the [Penn Treebank tagset](https://www.nltk.org/book/ch05.html) for the English language.\n",
    "\n",
    "**UPenn Tagset**\n",
    "\n",
    "    CC — coordinating conjunction\n",
    "    CD — cardinal digit\n",
    "    DT — determiner\n",
    "    EX — existential there (“there is”, “there exists”)\n",
    "    FW — foreign word\n",
    "    IN — preposition/subordinating conjunction\n",
    "    JJ — adjective (‘big’)\n",
    "    JJR — adjective, comparative (‘bigger’)\n",
    "    JJS — adjective, superlative (‘biggest’)\n",
    "    LS — list marker\n",
    "    MD — modal ('could', 'will')\n",
    "    NN — noun, singular (‘desk’)\n",
    "    NNS — noun plural (‘desks’)\n",
    "    NNP — proper noun, singular (‘Harrison’)\n",
    "    NNPS — proper noun, plural (‘Americans’)\n",
    "    PDT — predeterminer (‘all the kids’)\n",
    "    POS — possessive ending ('parent’s')\n",
    "    PRP — personal pronoun ('I', 'he', 'she')\n",
    "    PRPS — possessive pronoun ('my', 'his', 'hers')\n",
    "    RB — adverb ('very', 'silently')\n",
    "    RBR — adverb, comparative ('better')\n",
    "    RBS — adverb, superlative ('best')\n",
    "    RP — particle ('give up')\n",
    "    TO — to-particle ('to go')\n",
    "    UH — interjection ('errrrrrrrm')\n",
    "    VB — verb, base form ('take')\n",
    "    VBD — verb, past tense ('took')\n",
    "    VBG — verb, gerund/present participle ('taking')\n",
    "    VBN — verb, past participle ('taken')\n",
    "    VBP — verb, sing. present, non-3d ('take')\n",
    "    VBZ — verb, 3rd person sing. present ('takes')\n",
    "    WDT — wh-determiner ('which')\n",
    "    WP — wh-pronoun ('who', 'what')\n",
    "    WP — possessive wh-pronoun ('whose')\n",
    "    WRB — wh-abverb ('where', 'when')\n",
    "\n",
    "There is a [more modern and language independent tagset](http://universaldependencies.org/u/pos/) used within the [Universal Dependencies](http://universaldependencies.org/) framework. Each part of speech also has a set of features (e.g. nouns can have *number, case, gender*; verbs can have *tense, person, number* etc.), which are described [here](https://universaldependencies.org/u/feat/index.html). You can change the default UPenn tagset to UPOS by specifying the `tagset='universal'` in NLTK's `pos_tag` function.\n",
    "\n",
    "**UPOS tagset**\n",
    "\n",
    "    ADJ: adjective\n",
    "    ADP: adposition\n",
    "    ADV: adverb\n",
    "    AUX: auxiliary\n",
    "    CCONJ: coordinating conjunction\n",
    "    DET: determiner\n",
    "    INTJ: interjection\n",
    "    NOUN: noun\n",
    "    NUM: numeral\n",
    "    PART: particle\n",
    "    PRON: pronoun\n",
    "    PROPN: proper noun\n",
    "    PUNCT: punctuation\n",
    "    SCONJ: subordinating conjunction\n",
    "    SYM: symbol\n",
    "    VERB: verb\n",
    "    X: other\n",
    "\n",
    "\n",
    "The `pos_tag` function uses a so-called [PerceptronTagger](http://www.nltk.org/api/nltk.tag.html#nltk.tag.perceptron.PerceptronTagger). The model was trained on on Sections 00-18 of the Wall Street Journal sections of OntoNotes 5. The original implementation comes from Matthew Honnibal (you can read more about it [here](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)), it outperforms the predecessor maximum entropy POS model in NLTK. \n",
    "\n",
    "\n",
    "You can also create your own tagger which can **learn** from annotated data. This topic will be covered in detail in Lecture 4 on sequence modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdll5WGStXqH"
   },
   "outputs": [],
   "source": [
    "from nltk.tag import pos_tag\n",
    "pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Te6rzFTLOvpk"
   },
   "outputs": [],
   "source": [
    "pos_tag(tokens, tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3Jyqp5ztXqI"
   },
   "source": [
    "### Can you identify any problems with the tagging of the sentence above?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RA4X4gQDsFRR"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
