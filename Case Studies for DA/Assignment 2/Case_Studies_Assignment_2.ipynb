{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXvmvRi2uyfX",
    "outputId": "8b616807-7c87-4023-b247-06bcfaba585c"
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HzUzVd6bvjtj"
   },
   "outputs": [],
   "source": [
    "# reading images\n",
    "class ReadData():\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "    \n",
    "    def read(self):\n",
    "        images = []\n",
    "        for dirname, _, filenames in glob.glob(self.path):\n",
    "            print(filenames)\n",
    "            for filename in filenames:\n",
    "                pathname = os.path.join(dirname, filename)\n",
    "                image = Image.open(pathname)\n",
    "                image = image.resize((224, 224))\n",
    "                images.append(np.array(image, dtype = np.int64))\n",
    "\n",
    "        return images\n",
    "\n",
    "alpacaData = ReadData('/dataset/alpaca')\n",
    "\n",
    "notAlpacaData = ReadData('/dataset/not alpaca')\n",
    "\n",
    "alpacaImages = alpacaData.read()\n",
    "notAlpacaImages = notAlpacaData.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpacaImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RckH2LLSxNhU"
   },
   "outputs": [],
   "source": [
    "# preprocessing images\n",
    "class PreprocessImages():\n",
    "  def __init__(self):\n",
    "    pass\n",
    "\n",
    "  def normaliseImages(self, images):\n",
    "    normalisedImages = []\n",
    "    for image in images:\n",
    "      normalisedImages.append(image/255)\n",
    "\n",
    "    return normalisedImages\n",
    "\n",
    "preprocessImages = PreprocessImages()\n",
    "normalisedAlpacas = preprocessImages.normaliseImages(alpacaImages)\n",
    "normalisedNotAlpacas = preprocessImages.normaliseImages(notAlpacaImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNr-Z5mi18Sx",
    "outputId": "9ef7e9c8-42ef-48c4-e403-cac81b458d7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [images, label]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Smitesh\\AppData\\Local\\Temp/ipykernel_21852/2380145603.py:15: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  dataset.loc[:len(trueImages)-1, 'label'] = 1\n",
      "C:\\Users\\Smitesh\\AppData\\Local\\Temp/ipykernel_21852/2380145603.py:16: FutureWarning: Slicing a positional slice with .loc is not supported, and will raise TypeError in a future version.  Use .loc with labels or .iloc with positions instead.\n",
      "  dataset.loc[len(trueImages):, 'label'] = 0\n"
     ]
    }
   ],
   "source": [
    "# combining the two class images into one dataset\n",
    "class CreateDataset():\n",
    "  def __self__(self):\n",
    "    pass\n",
    "\n",
    "  def createDataset(self, trueImages, falseImages):\n",
    "      dataset = pd.DataFrame(columns = ['images', 'label'])\n",
    "\n",
    "      for image in trueImages:\n",
    "        dataset.loc[len(dataset), 'images'] = image\n",
    "    \n",
    "      for image in falseImages:\n",
    "        dataset.loc[len(dataset), 'images'] = image\n",
    "\n",
    "      dataset.loc[:len(trueImages)-1, 'label'] = 1\n",
    "      dataset.loc[len(trueImages):, 'label'] = 0\n",
    "      return dataset\n",
    "\n",
    "createDataset = CreateDataset()\n",
    "dataset = createDataset.createDataset(normalisedAlpacas, normalisedNotAlpacas)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "iuIOhp9y7Jvn",
    "outputId": "271512f6-d44d-4f93-c13e-9c2017d5d26e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21852/1497203229.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# splitting the dataset into training, validation, and testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m trainingData, validationData = train_test_split(dataset,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                              \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                              \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m110323\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                              stratify = dataset.label)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Main\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2447\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2448\u001b[1;33m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[0;32m   2449\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2450\u001b[0m     )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Main\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   2127\u001b[0m             \u001b[1;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m             \u001b[1;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# splitting the dataset into training, validation, and testing\n",
    "trainingData, validationData = train_test_split(dataset,\n",
    "                                             test_size = 0.3,\n",
    "                                             random_state = 110323,\n",
    "                                             stratify = dataset.label)\n",
    "\n",
    "validationData, testingData = train_test_split(validationData,\n",
    "                                             test_size = 0.5,\n",
    "                                             random_state = 110323,\n",
    "                                             stratify = validationData.label)\n",
    "\n",
    "trainingData = trainingData.reset_index().drop(columns=['index'])\n",
    "validationData = validationData.reset_index().drop(columns=['index'])\n",
    "testingData = testingData.reset_index().drop(columns=['index'])\n",
    "print(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JOV_exvNEvTZ"
   },
   "outputs": [],
   "source": [
    "# convolutional neural network structure\n",
    "class ConvolutionalNetwork():\n",
    "    def __self__(self, imageShape):\n",
    "        self.stride = 1\n",
    "        self.layer1 = 16\n",
    "        self.layer2 = 12\n",
    "        self.layer3 = 8\n",
    "\n",
    "    def layerOne(self, images, imageShape):\n",
    "        weightMatrices = []\n",
    "        print(self.layer1)\n",
    "        for i in range(self.layer1):\n",
    "          print(i)\n",
    "            # print(np.random.normal(loc = 0.0, scale = 0.1, size = imageShape))\n",
    "\n",
    "    def train(self, images, imageShape):\n",
    "        self.layerOne(self, images, imageShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "id": "L2gh2j3AIQmE",
    "outputId": "023eea2f-c86c-4549-8efa-2f44380185ce"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-40840e2dd24c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolutionalNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# # print(trainingData['images'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(trainingData['images'][0].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainingData' is not defined"
     ]
    }
   ],
   "source": [
    "cnn = ConvolutionalNetwork()\n",
    "cnn.train(trainingData['images'].tolist(), trainingData['images'][0].shape)\n",
    "# # print(trainingData['images'])\n",
    "# print(trainingData['images'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njlJYI4IIaVj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
