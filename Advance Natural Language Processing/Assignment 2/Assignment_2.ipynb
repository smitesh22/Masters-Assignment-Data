{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSCr4xKJnhZ6"
   },
   "source": [
    "# Overview\n",
    "**Assignment 2** focuses on the training on a Neural Machine Translation (NMT) system for English-Irish translation where English is the source language and Irish is the target language. \n",
    "\n",
    "**Grading Policy** \n",
    "Assignment 2 is graded and will be worth 25% of your overall grade. This assignment is worth a total of 50 points distributed over the tasks below.  Please note that this is an individual assignment and you must not work with other students to complete this assessment. Any copying from other students, from student exercises from previous years, and any internet resources will not be tolerated. Plagiarised assignments will receive zero marks and the students who commit this act will be reported. Feel free to reach out to the TAs and instructors if you have any questions.\n",
    "\n",
    "## Task 1 - Data Collection and Preprocessing (10 points)\n",
    "## Task 1a. Data Loading (5 pts)\n",
    "Dataset: https://www.dropbox.com/s/zkgclwc9hrx7y93/DGT-en-ga.txt.zip?dl=0 \n",
    "*  Download a English-Irish dataset and decompress it. The `DGT.en-ga.en` file contains a list english sentences and `DGT.en-ga.ga` contains the paralell Irish sentences. Read both files into the Jupyter environment and load them into a pandas dataframe. \n",
    "* Randomly sample 12,000 rows.\n",
    "* Split the sampled data into train (10k), development (1k) and test set (1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mjieQgrsocnh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#reading lines from datasets for english and irish data\n",
    "english_data = pd.read_csv(\"DGT-en-ga.txt\\DGT.en-ga.en\", sep = '\\t', names = [\"Englishtext\"])\n",
    "irish_data = pd.read_csv(\"DGT-en-ga.txt\\DGT.en-ga.ga\", sep = '\\t', names = [\"Irishtext\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([english_data, irish_data], axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(181143)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Irishlen\"] = df[\"Irishtext\"].apply(lambda x: len(x.split(\" \")))\n",
    "df[\"Englishlen\"] = df[\"Englishtext\"].apply(lambda x: len(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Englishtext</th>\n",
       "      <th>Irishtext</th>\n",
       "      <th>Irishlen</th>\n",
       "      <th>Englishlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Procès-verbal of rectification to the Conventi...</td>\n",
       "      <td>Miontuairisc cheartaitheach maidir le Coinbhin...</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Official Journal of the European Union L 147 ...</td>\n",
       "      <td>(Iris Oifigiúil an Aontais Eorpaigh L 147 an 1...</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This rectification has been carried out by mea...</td>\n",
       "      <td>Rinneadh an ceartúchán seo le miontuairisc che...</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>On pages 33-34, Annex I:</td>\n",
       "      <td>Ar leathanaigh 33-34, Iarscríbhinn I:</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the entries for the States below are rectified...</td>\n",
       "      <td>maidir leis na hiontrálacha le haghaidh na Stá...</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181138</th>\n",
       "      <td>For the Council</td>\n",
       "      <td>Airteagal 2.5 (Coimirce talmhaíochta), agus Ai...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181139</th>\n",
       "      <td>Position of the European Parliament of 31 Janu...</td>\n",
       "      <td>ciallaíonn ‘idirthréimhse’, i ndáil le hearra ...</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181140</th>\n",
       "      <td>Regulation (EU) No 1305/2013 of the European P...</td>\n",
       "      <td>Airteagal 18 (Coimirciú) d'Iarscríbhinn 2-C ma...</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181141</th>\n",
       "      <td>Regulation (EU) 2017/2393 of the European Parl...</td>\n",
       "      <td>I rith na 10 mbliana tar éis theacht i bhfeidh...</td>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181142</th>\n",
       "      <td>Regulation (EU) No 1307/2013 of the European P...</td>\n",
       "      <td>nach gcuirfidh an Páirtí eile i bhfeidhm Riala...</td>\n",
       "      <td>32</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>181143 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Englishtext  \\\n",
       "0       Procès-verbal of rectification to the Conventi...   \n",
       "1       (Official Journal of the European Union L 147 ...   \n",
       "2       This rectification has been carried out by mea...   \n",
       "3                                On pages 33-34, Annex I:   \n",
       "4       the entries for the States below are rectified...   \n",
       "...                                                   ...   \n",
       "181138                                    For the Council   \n",
       "181139  Position of the European Parliament of 31 Janu...   \n",
       "181140  Regulation (EU) No 1305/2013 of the European P...   \n",
       "181141  Regulation (EU) 2017/2393 of the European Parl...   \n",
       "181142  Regulation (EU) No 1307/2013 of the European P...   \n",
       "\n",
       "                                                Irishtext  Irishlen  \\\n",
       "0       Miontuairisc cheartaitheach maidir le Coinbhin...        28   \n",
       "1       (Iris Oifigiúil an Aontais Eorpaigh L 147 an 1...        20   \n",
       "2       Rinneadh an ceartúchán seo le miontuairisc che...        28   \n",
       "3                   Ar leathanaigh 33-34, Iarscríbhinn I:         5   \n",
       "4       maidir leis na hiontrálacha le haghaidh na Stá...        14   \n",
       "...                                                   ...       ...   \n",
       "181138  Airteagal 2.5 (Coimirce talmhaíochta), agus Ai...        12   \n",
       "181139  ciallaíonn ‘idirthréimhse’, i ndáil le hearra ...        43   \n",
       "181140  Airteagal 18 (Coimirciú) d'Iarscríbhinn 2-C ma...        10   \n",
       "181141  I rith na 10 mbliana tar éis theacht i bhfeidh...        35   \n",
       "181142  nach gcuirfidh an Páirtí eile i bhfeidhm Riala...        32   \n",
       "\n",
       "        Englishlen  \n",
       "0               27  \n",
       "1               12  \n",
       "2               33  \n",
       "3                5  \n",
       "4               10  \n",
       "...            ...  \n",
       "181138           3  \n",
       "181139          23  \n",
       "181140          37  \n",
       "181141         107  \n",
       "181142          45  \n",
       "\n",
       "[181143 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Irishlen\"] > 28]\n",
    "df = df.sample(12000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejav7LUqokNc"
   },
   "source": [
    "## Task 1b. Preprocessing (5 pts)\n",
    "* Add '<bof\\>' to denote beginning of sentence and '<eos\\>' to denote the end of the sentence to each target line.\n",
    "* Perform the following pre-processing steps:\n",
    "  * Lowercase the text\n",
    "  * Remove all punctuation\n",
    "  * tokenize the text \n",
    "*  Build seperate vocabularies for each language. \n",
    "  * Assign each unique word an id value \n",
    "*Print statistics on the selected dataset:\n",
    "  * Number of samples\n",
    "  * Number of unique source language tokens\n",
    "  * Number of unique target language tokens\n",
    "  * Max sequence length of source language\n",
    "  * Max sequence length of target language\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CGC-CvmHojdB"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Your code here\n",
    "class Preprocess:\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe        \n",
    "        self.englishwords = []\n",
    "        self.irishwords = []\n",
    "        self.english_valuecounts = {}\n",
    "        self.irish_valuecounts = {}\n",
    "        self.english_dict = {\"PAD\": 0, \"<bof>\": 1, \"<eos>\": 2}\n",
    "        self.english_word2idx = {0: 'PAD', 1: \"<bof>\", 2 : \"<eof>\"}\n",
    "        self.irish_dict = {\"PAD\": 0, \"<bof>\": 1, \"<eos>\": 2}\n",
    "        self.irish_word2idx = {0: 'PAD', 1: \"<bof>\", 2 : \"<eof>\"}\n",
    "        self.english_unique_words = 0\n",
    "        self.irish_unique_words = 0\n",
    "        self.english_word_count = 0\n",
    "        self.irish_word_count = 0\n",
    "        self.encoded_sentence_english = 0\n",
    "        self.encoded_sentence_irish = 0\n",
    "        \n",
    "        \n",
    "    #1. Add '<bof>' to denote beginning of sentence and '<eos>' to denote the end of the sentence to each target line.\n",
    "    def sentenceTags(self):\n",
    "        self.dataframe['Englishtext'] = self.dataframe['Englishtext'].apply(lambda x: '<bof> '+ x + ' <eos>')\n",
    "        self.dataframe['Irishtext'] = self.dataframe['Irishtext'].apply(lambda x: '<bof> '+ x + ' <eos>')\n",
    "        \n",
    "        return self.dataframe\n",
    "    \n",
    "    def preprocess(self):\n",
    "        #Lowercase the text\n",
    "        self.dataframe['Englishtext'] = self.dataframe['Englishtext'].apply(lambda x: str(x).lower())\n",
    "        self.dataframe['Irishtext'] = self.dataframe['Irishtext'].apply(lambda x: x.lower())\n",
    "        \n",
    "        #Remove all punctuation\n",
    "        self.dataframe['Englishtext'] = self.dataframe['Englishtext'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "        self.dataframe['Irishtext'] = self.dataframe['Irishtext'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "        \n",
    "        return self.dataframe\n",
    "        \n",
    "    #tokenize the text\n",
    "    def tokenize(self):\n",
    "        self.dataframe['EnglishTokens'] = self.dataframe['Englishtext'].apply(lambda x: x.split(\" \"))\n",
    "        self.dataframe['IrishTokens'] = self.dataframe['Irishtext'].apply(lambda x: x.split(\" \"))\n",
    "        \n",
    "        return self.dataframe\n",
    "    \n",
    "    def create_dict(self):\n",
    "        self.englishwords = self.dataframe['Englishtext'].str.cat().split(' ')\n",
    "        self.irishwords = self.dataframe['Irishtext'].str.cat().split(' ')\n",
    "        \n",
    "        \n",
    "        #create a word count dictonary\n",
    "        #creat a index to word \n",
    "        value = 3\n",
    "        for word in self.englishwords:\n",
    "            if word not in self.english_dict and word != '':\n",
    "                self.english_dict[word] = value\n",
    "                self.english_word2idx[value] = word\n",
    "                value += 1\n",
    "        value = 3\n",
    "        for word in self.irishwords:\n",
    "            if word not in self.irish_dict and word != '':\n",
    "                self.irish_dict[word] = value\n",
    "                self.irish_word2idx[value] = word\n",
    "                value += 1\n",
    "\n",
    "        \n",
    "        self.english_dict = dict(sorted(self.english_dict.items(), key = lambda x:x[1]))\n",
    "        self.irish_dict = dict(sorted(self.irish_dict.items(), key = lambda x:x[1]))\n",
    "        \n",
    "        \n",
    "        #Assign each unique word an id value \n",
    "        self.english_unique_words = set(self.englishwords)\n",
    "        self.irish_unique_words = set(self.irishwords)\n",
    "        \n",
    "        self.english_word_count = len(self.english_unique_words)\n",
    "        self.irish_word_count = len(self.irish_unique_words)\n",
    "        \n",
    "        print(\"Created dictonaries for indexing unique words and value counts\")\n",
    "        \n",
    "    \n",
    "    def encode_sentence(self):\n",
    "        self.encoded_sentence_english = [[preprocess.english_dict[token] for token in sentence \n",
    "                             if token != ''] for sentence in preprocess.dataframe.EnglishTokens]\n",
    "        self.encoded_sentence_irish = [[preprocess.irish_dict[token] for token in sentence \n",
    "                             if token != ''] for sentence in preprocess.dataframe.IrishTokens]\n",
    "        \n",
    "    \"\"\"\n",
    "        Print statistics on the selected dataset:\n",
    "        Number of samples\n",
    "        Number of unique source language tokens\n",
    "        Number of unique target language tokens\n",
    "        Max sequence length of source language\n",
    "        Max sequence length of target language\n",
    "    \"\"\"\n",
    "    \n",
    "    def print_info(self):\n",
    "        print(\"Statistics on dataset\\n\\n\")\n",
    "        \n",
    "        print(\"Number of samples: \"+ str(len(self.dataframe)))\n",
    "        print(\"Unique words in english set: \"+ str(self.english_word_count))\n",
    "        print(\"Unique words in irish set: \"+ str(self.irish_word_count))\n",
    "        print(\"Max sequence length for source language : \"+ str(max(self.dataframe.Englishlen)))\n",
    "        print(\"Max sequence length for target language : \"+ str(max(self.dataframe.Irishlen)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Preprocess(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Englishtext</th>\n",
       "      <th>Irishtext</th>\n",
       "      <th>Irishlen</th>\n",
       "      <th>Englishlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158873</td>\n",
       "      <td>article 21b and c</td>\n",
       "      <td>gan dochar dfhreagrachtaí an oibreora aerártha...</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86645</td>\n",
       "      <td>the commission shall send the information refe...</td>\n",
       "      <td>ceadófar do shoithí mórscála peiligeacha gabhá...</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138191</td>\n",
       "      <td>for the purposes referred to in points a b and...</td>\n",
       "      <td>féadfaidh an coimisiún gníomhartha cur chun fe...</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22757</td>\n",
       "      <td>adapting the production and output of producer...</td>\n",
       "      <td>cinnfidh na ballstáit an tuaslíon agus an tíos...</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111506</td>\n",
       "      <td>the possibility of becoming a member the condi...</td>\n",
       "      <td>ba é an chonclúid a baineadh as an meastóireac...</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>147034</td>\n",
       "      <td>steered axles number and position</td>\n",
       "      <td>cuirfidh an tiarratasóir isteach ráiteas ón mo...</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>105707</td>\n",
       "      <td>active implantable devices and if appropriate ...</td>\n",
       "      <td>go háirithe tabharfar aird ar an tsábháilteach...</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>72904</td>\n",
       "      <td>the supervisory authorities concerned shall no...</td>\n",
       "      <td>i gcás ina mbeidh bunaíochtaí ag an rialaitheo...</td>\n",
       "      <td>58</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>157368</td>\n",
       "      <td>when the information referred to in article 72...</td>\n",
       "      <td>más rud é tar éis an chomhairliúcháin sin go m...</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>32975</td>\n",
       "      <td>infrastructure requirements</td>\n",
       "      <td>féadfaidh eangacha agus na saoráidí eile is gá...</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                        Englishtext  \\\n",
       "0      158873                                  article 21b and c   \n",
       "1       86645  the commission shall send the information refe...   \n",
       "2      138191  for the purposes referred to in points a b and...   \n",
       "3       22757  adapting the production and output of producer...   \n",
       "4      111506  the possibility of becoming a member the condi...   \n",
       "...       ...                                                ...   \n",
       "11995  147034                  steered axles number and position   \n",
       "11996  105707  active implantable devices and if appropriate ...   \n",
       "11997   72904  the supervisory authorities concerned shall no...   \n",
       "11998  157368  when the information referred to in article 72...   \n",
       "11999   32975                        infrastructure requirements   \n",
       "\n",
       "                                               Irishtext  Irishlen  Englishlen  \n",
       "0      gan dochar dfhreagrachtaí an oibreora aerártha...        69           4  \n",
       "1      ceadófar do shoithí mórscála peiligeacha gabhá...        65          57  \n",
       "2      féadfaidh an coimisiún gníomhartha cur chun fe...        31          49  \n",
       "3      cinnfidh na ballstáit an tuaslíon agus an tíos...        35          18  \n",
       "4      ba é an chonclúid a baineadh as an meastóireac...        34          16  \n",
       "...                                                  ...       ...         ...  \n",
       "11995  cuirfidh an tiarratasóir isteach ráiteas ón mo...        39           5  \n",
       "11996  go háirithe tabharfar aird ar an tsábháilteach...        34          36  \n",
       "11997  i gcás ina mbeidh bunaíochtaí ag an rialaitheo...        58          28  \n",
       "11998  más rud é tar éis an chomhairliúcháin sin go m...       119          48  \n",
       "11999  féadfaidh eangacha agus na saoráidí eile is gá...        40           2  \n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Englishtext</th>\n",
       "      <th>Irishtext</th>\n",
       "      <th>Irishlen</th>\n",
       "      <th>Englishlen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158873</td>\n",
       "      <td>&lt;bof&gt; article 21b and c &lt;eos&gt;</td>\n",
       "      <td>&lt;bof&gt; gan dochar dfhreagrachtaí an oibreora ae...</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86645</td>\n",
       "      <td>&lt;bof&gt; the commission shall send the informatio...</td>\n",
       "      <td>&lt;bof&gt; ceadófar do shoithí mórscála peiligeacha...</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138191</td>\n",
       "      <td>&lt;bof&gt; for the purposes referred to in points a...</td>\n",
       "      <td>&lt;bof&gt; féadfaidh an coimisiún gníomhartha cur c...</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22757</td>\n",
       "      <td>&lt;bof&gt; adapting the production and output of pr...</td>\n",
       "      <td>&lt;bof&gt; cinnfidh na ballstáit an tuaslíon agus a...</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111506</td>\n",
       "      <td>&lt;bof&gt; the possibility of becoming a member the...</td>\n",
       "      <td>&lt;bof&gt; ba é an chonclúid a baineadh as an meast...</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>147034</td>\n",
       "      <td>&lt;bof&gt; steered axles number and position &lt;eos&gt;</td>\n",
       "      <td>&lt;bof&gt; cuirfidh an tiarratasóir isteach ráiteas...</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>105707</td>\n",
       "      <td>&lt;bof&gt; active implantable devices and if approp...</td>\n",
       "      <td>&lt;bof&gt; go háirithe tabharfar aird ar an tsábhái...</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>72904</td>\n",
       "      <td>&lt;bof&gt; the supervisory authorities concerned sh...</td>\n",
       "      <td>&lt;bof&gt; i gcás ina mbeidh bunaíochtaí ag an rial...</td>\n",
       "      <td>58</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>157368</td>\n",
       "      <td>&lt;bof&gt; when the information referred to in arti...</td>\n",
       "      <td>&lt;bof&gt; más rud é tar éis an chomhairliúcháin si...</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>32975</td>\n",
       "      <td>&lt;bof&gt; infrastructure requirements &lt;eos&gt;</td>\n",
       "      <td>&lt;bof&gt; féadfaidh eangacha agus na saoráidí eile...</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                        Englishtext  \\\n",
       "0      158873                      <bof> article 21b and c <eos>   \n",
       "1       86645  <bof> the commission shall send the informatio...   \n",
       "2      138191  <bof> for the purposes referred to in points a...   \n",
       "3       22757  <bof> adapting the production and output of pr...   \n",
       "4      111506  <bof> the possibility of becoming a member the...   \n",
       "...       ...                                                ...   \n",
       "11995  147034      <bof> steered axles number and position <eos>   \n",
       "11996  105707  <bof> active implantable devices and if approp...   \n",
       "11997   72904  <bof> the supervisory authorities concerned sh...   \n",
       "11998  157368  <bof> when the information referred to in arti...   \n",
       "11999   32975            <bof> infrastructure requirements <eos>   \n",
       "\n",
       "                                               Irishtext  Irishlen  Englishlen  \n",
       "0      <bof> gan dochar dfhreagrachtaí an oibreora ae...        69           4  \n",
       "1      <bof> ceadófar do shoithí mórscála peiligeacha...        65          57  \n",
       "2      <bof> féadfaidh an coimisiún gníomhartha cur c...        31          49  \n",
       "3      <bof> cinnfidh na ballstáit an tuaslíon agus a...        35          18  \n",
       "4      <bof> ba é an chonclúid a baineadh as an meast...        34          16  \n",
       "...                                                  ...       ...         ...  \n",
       "11995  <bof> cuirfidh an tiarratasóir isteach ráiteas...        39           5  \n",
       "11996  <bof> go háirithe tabharfar aird ar an tsábhái...        34          36  \n",
       "11997  <bof> i gcás ina mbeidh bunaíochtaí ag an rial...        58          28  \n",
       "11998  <bof> más rud é tar éis an chomhairliúcháin si...       119          48  \n",
       "11999  <bof> féadfaidh eangacha agus na saoráidí eile...        40           2  \n",
       "\n",
       "[12000 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.sentenceTags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Englishtext</th>\n",
       "      <th>Irishtext</th>\n",
       "      <th>Irishlen</th>\n",
       "      <th>Englishlen</th>\n",
       "      <th>EnglishTokens</th>\n",
       "      <th>IrishTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>158873</td>\n",
       "      <td>&lt;bof&gt; article 21b and c &lt;eos&gt;</td>\n",
       "      <td>&lt;bof&gt; gan dochar dfhreagrachtaí an oibreora ae...</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>[&lt;bof&gt;, article, 21b, and, c, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;bof&gt;, gan, dochar, dfhreagrachtaí, an, oibre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86645</td>\n",
       "      <td>&lt;bof&gt; the commission shall send the informatio...</td>\n",
       "      <td>&lt;bof&gt; ceadófar do shoithí mórscála peiligeacha...</td>\n",
       "      <td>65</td>\n",
       "      <td>57</td>\n",
       "      <td>[&lt;bof&gt;, the, commission, shall, send, the, inf...</td>\n",
       "      <td>[&lt;bof&gt;, ceadófar, do, shoithí, mórscála, peili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138191</td>\n",
       "      <td>&lt;bof&gt; for the purposes referred to in points a...</td>\n",
       "      <td>&lt;bof&gt; féadfaidh an coimisiún gníomhartha cur c...</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "      <td>[&lt;bof&gt;, for, the, purposes, referred, to, in, ...</td>\n",
       "      <td>[&lt;bof&gt;, féadfaidh, an, coimisiún, gníomhartha,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22757</td>\n",
       "      <td>&lt;bof&gt; adapting the production and output of pr...</td>\n",
       "      <td>&lt;bof&gt; cinnfidh na ballstáit an tuaslíon agus a...</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>[&lt;bof&gt;, adapting, the, production, and, output...</td>\n",
       "      <td>[&lt;bof&gt;, cinnfidh, na, ballstáit, an, tuaslíon,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111506</td>\n",
       "      <td>&lt;bof&gt; the possibility of becoming a member the...</td>\n",
       "      <td>&lt;bof&gt; ba é an chonclúid a baineadh as an meast...</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>[&lt;bof&gt;, the, possibility, of, becoming, a, mem...</td>\n",
       "      <td>[&lt;bof&gt;, ba, é, an, chonclúid, a, baineadh, as,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>147034</td>\n",
       "      <td>&lt;bof&gt; steered axles number and position &lt;eos&gt;</td>\n",
       "      <td>&lt;bof&gt; cuirfidh an tiarratasóir isteach ráiteas...</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>[&lt;bof&gt;, steered, axles, number, and, position,...</td>\n",
       "      <td>[&lt;bof&gt;, cuirfidh, an, tiarratasóir, isteach, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>105707</td>\n",
       "      <td>&lt;bof&gt; active implantable devices and if approp...</td>\n",
       "      <td>&lt;bof&gt; go háirithe tabharfar aird ar an tsábhái...</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>[&lt;bof&gt;, active, implantable, devices, and, if,...</td>\n",
       "      <td>[&lt;bof&gt;, go, háirithe, tabharfar, aird, ar, an,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>72904</td>\n",
       "      <td>&lt;bof&gt; the supervisory authorities concerned sh...</td>\n",
       "      <td>&lt;bof&gt; i gcás ina mbeidh bunaíochtaí ag an rial...</td>\n",
       "      <td>58</td>\n",
       "      <td>28</td>\n",
       "      <td>[&lt;bof&gt;, the, supervisory, authorities, concern...</td>\n",
       "      <td>[&lt;bof&gt;, i, gcás, ina, mbeidh, bunaíochtaí, ag,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>157368</td>\n",
       "      <td>&lt;bof&gt; when the information referred to in arti...</td>\n",
       "      <td>&lt;bof&gt; más rud é tar éis an chomhairliúcháin si...</td>\n",
       "      <td>119</td>\n",
       "      <td>48</td>\n",
       "      <td>[&lt;bof&gt;, when, the, information, referred, to, ...</td>\n",
       "      <td>[&lt;bof&gt;, más, rud, é, tar, éis, an, chomhairliú...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>32975</td>\n",
       "      <td>&lt;bof&gt; infrastructure requirements &lt;eos&gt;</td>\n",
       "      <td>&lt;bof&gt; féadfaidh eangacha agus na saoráidí eile...</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>[&lt;bof&gt;, infrastructure, requirements, &lt;eos&gt;]</td>\n",
       "      <td>[&lt;bof&gt;, féadfaidh, eangacha, agus, na, saoráid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index                                        Englishtext  \\\n",
       "0      158873                      <bof> article 21b and c <eos>   \n",
       "1       86645  <bof> the commission shall send the informatio...   \n",
       "2      138191  <bof> for the purposes referred to in points a...   \n",
       "3       22757  <bof> adapting the production and output of pr...   \n",
       "4      111506  <bof> the possibility of becoming a member the...   \n",
       "...       ...                                                ...   \n",
       "11995  147034      <bof> steered axles number and position <eos>   \n",
       "11996  105707  <bof> active implantable devices and if approp...   \n",
       "11997   72904  <bof> the supervisory authorities concerned sh...   \n",
       "11998  157368  <bof> when the information referred to in arti...   \n",
       "11999   32975            <bof> infrastructure requirements <eos>   \n",
       "\n",
       "                                               Irishtext  Irishlen  \\\n",
       "0      <bof> gan dochar dfhreagrachtaí an oibreora ae...        69   \n",
       "1      <bof> ceadófar do shoithí mórscála peiligeacha...        65   \n",
       "2      <bof> féadfaidh an coimisiún gníomhartha cur c...        31   \n",
       "3      <bof> cinnfidh na ballstáit an tuaslíon agus a...        35   \n",
       "4      <bof> ba é an chonclúid a baineadh as an meast...        34   \n",
       "...                                                  ...       ...   \n",
       "11995  <bof> cuirfidh an tiarratasóir isteach ráiteas...        39   \n",
       "11996  <bof> go háirithe tabharfar aird ar an tsábhái...        34   \n",
       "11997  <bof> i gcás ina mbeidh bunaíochtaí ag an rial...        58   \n",
       "11998  <bof> más rud é tar éis an chomhairliúcháin si...       119   \n",
       "11999  <bof> féadfaidh eangacha agus na saoráidí eile...        40   \n",
       "\n",
       "       Englishlen                                      EnglishTokens  \\\n",
       "0               4               [<bof>, article, 21b, and, c, <eos>]   \n",
       "1              57  [<bof>, the, commission, shall, send, the, inf...   \n",
       "2              49  [<bof>, for, the, purposes, referred, to, in, ...   \n",
       "3              18  [<bof>, adapting, the, production, and, output...   \n",
       "4              16  [<bof>, the, possibility, of, becoming, a, mem...   \n",
       "...           ...                                                ...   \n",
       "11995           5  [<bof>, steered, axles, number, and, position,...   \n",
       "11996          36  [<bof>, active, implantable, devices, and, if,...   \n",
       "11997          28  [<bof>, the, supervisory, authorities, concern...   \n",
       "11998          48  [<bof>, when, the, information, referred, to, ...   \n",
       "11999           2       [<bof>, infrastructure, requirements, <eos>]   \n",
       "\n",
       "                                             IrishTokens  \n",
       "0      [<bof>, gan, dochar, dfhreagrachtaí, an, oibre...  \n",
       "1      [<bof>, ceadófar, do, shoithí, mórscála, peili...  \n",
       "2      [<bof>, féadfaidh, an, coimisiún, gníomhartha,...  \n",
       "3      [<bof>, cinnfidh, na, ballstáit, an, tuaslíon,...  \n",
       "4      [<bof>, ba, é, an, chonclúid, a, baineadh, as,...  \n",
       "...                                                  ...  \n",
       "11995  [<bof>, cuirfidh, an, tiarratasóir, isteach, r...  \n",
       "11996  [<bof>, go, háirithe, tabharfar, aird, ar, an,...  \n",
       "11997  [<bof>, i, gcás, ina, mbeidh, bunaíochtaí, ag,...  \n",
       "11998  [<bof>, más, rud, é, tar, éis, an, chomhairliú...  \n",
       "11999  [<bof>, féadfaidh, eangacha, agus, na, saoráid...  \n",
       "\n",
       "[12000 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dictonaries for indexing unique words and value counts\n"
     ]
    }
   ],
   "source": [
    "preprocess.create_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics on dataset\n",
      "\n",
      "\n",
      "Number of samples: 12000\n",
      "Unique words in english set: 12173\n",
      "Unique words in irish set: 22933\n",
      "Max sequence length for source language : 307\n",
      "Max sequence length for target language : 301\n"
     ]
    }
   ],
   "source": [
    "preprocess.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess.encode_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "def pad_features(english_tokens, irish_tokens):\n",
    "\n",
    "    source = pad_sequences(english_tokens, maxlen = 310, padding = 'post', truncating = 'post', value = 0)\n",
    "    target = pad_sequences(irish_tokens, maxlen = 310, padding = 'post', truncating = 'post', value = 0)\n",
    "        \n",
    "        \n",
    "    return source, target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source, data_target = pad_features(preprocess.encoded_sentence_english, preprocess.encoded_sentence_irish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of train source (12000, 310), and target (12000, 310)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shapes of train source {data_source.shape}, and target {data_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_source[0:8000]\n",
    "y_train = data_target[0:8000]\n",
    "\n",
    "X_test = data_source[8000:10000]\n",
    "y_test = data_target[8000:10000]\n",
    "\n",
    "X_val = data_source[10000:]\n",
    "y_val = data_target[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "train_dl = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.LongTensor(X_train),\n",
    "        torch.LongTensor(y_train)\n",
    "    ),\n",
    "    shuffle = True,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.LongTensor(X_val),\n",
    "        torch.LongTensor(y_val)\n",
    "    ),\n",
    "    shuffle = False,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.LongTensor(X_test),\n",
    "        torch.LongTensor(y_test)\n",
    "    ),\n",
    "    shuffle = False,\n",
    "    batch_size = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data : 8000   8000\n",
      "Test Data : 2000   2000\n",
      "Validation Data : 2000   2000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Data : \"+str(len(X_train)) + \"   \"+ str(len(y_train)))\n",
    "print(\"Test Data : \"+str(len(X_test)) + \"   \"+ str(len(y_test)))\n",
    "print(\"Validation Data : \"+str(len(X_val)) + \"   \"+ str(len(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 310]) torch.Size([64, 310])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dl:\n",
    "    print( batch[0].shape, batch[1].shape )\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oauhQ1fjsC69"
   },
   "source": [
    "## Task 2. Model Implementation and Training (30 pts)\n",
    "\n",
    "\n",
    "\n",
    "## Task 2a. Encoder-Decoder Model Implementation (10 pts)\n",
    "Implement an Encoder-Decoder model in Pytorch with the following components\n",
    "* A single layer RNN based encoder. \n",
    "* A single layer RNN based decoder\n",
    "* A Encoder-Decoder model based on the above components that support sequence-to-sequence modelling. For the encoder/decoder you can use RNN, LSTMs or GRU. Use a hidden dimension of 256 or less depending on your compute constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7gvR8hz0tMoG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# Your code here\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_vocab_size, hidden_dim, encoder_hid_dim, decoder_hid_dim , prob):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_vocab_size, hidden_dim)\n",
    "        self.rnn = nn.GRU(hidden_dim, encoder_hid_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(encoder_hid_dim * 2, decoder_hid_dim)\n",
    "        self.dropout = nn.Dropout(prob)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        embedding = self.dropout(self.embedding(src))\n",
    "        \n",
    "        outputs, hidden = self.rnn(embedding)\n",
    "        \n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2, :,:], hidden[-1,:,:]), dim = 1)))\n",
    "        return outputs, hidden\n",
    "    \n",
    "    \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2)))\n",
    "        \n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        return F.softmax(attention, dim = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, target_vocab_size, hidden_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.output_dim = target_vocab_size\n",
    "        self.attention = Attention(enc_hid_dim, dec_hid_dim)\n",
    "        \n",
    "        self.embedding = nn.Embedding(target_vocab_size, hidden_dim)\n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + hidden_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(\n",
    "                (enc_hid_dim * 2) + dec_hid_dim + hidden_dim,\n",
    "                target_vocab_size\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedding = self.dropout(self.embedding(input))\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        rnn_input = torch.cat((embedding, weighted), dim = 2)\n",
    "        \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        embedding = embedding.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediciton = self.fc_out(torch.cat((output, weighted, embedding), dim = 1))\n",
    "        \n",
    "        return predicitons, hidden.squeeze(0)\n",
    "        \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Model, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        batch_size = src.shape[1]\n",
    "        target_len = trg.shape[0]\n",
    "        \n",
    "        target_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(target_len, batch_size, target_vocab_size)\n",
    "        \n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "        \n",
    "        input = trg[0, :]\n",
    "    \n",
    "        for t in range(1, target_len):\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            \n",
    "            best = outputs.argmax(1)\n",
    "            \n",
    "            x = target[1] if random.random() < teacher_forcing_ratio else best\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqdYhxa1uiqF"
   },
   "source": [
    "## Task 2b. Training (10 pts)\n",
    "Implement the code to train the Encoder-Decoder model on the Irish-English data. You will write code for the following:\n",
    "* Training, validation and test dataloaders \n",
    "* A training loop which trains the model for 5 epoch. Evaluate the loop at the end of each Epoch. Print out the train perplexity and validation perplexity after each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4cZ-6zHtwkZn"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(preprocess.english_unique_words)\n",
    "OUTPUT_DIM = len(preprocess.irish_unique_words)\n",
    "\n",
    "ENC_EMB_DIM = 256\n",
    "DEC_EMB_DIM = 256\n",
    "\n",
    "ENC_HID_DIM = 128\n",
    "DEC_HID_DIM = 128\n",
    "\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(12173, 256)\n",
       "    (rnn): GRU(256, 128, bidirectional=True)\n",
       "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
       "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(22933, 256)\n",
       "    (rnn): GRU(512, 128)\n",
       "    (fc_out): Linear(in_features=640, out_features=22933, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(enc, dec)\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([310, 64])  :1\n",
      "torch.Size([310, 64])  :2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected size for first two dimensions of batch2 tensor to be: [64, 310] but got: [310, 64].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16912/3508749665.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\" :2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0moutput_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Main\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16912/3449655598.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Main\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16912/3449655598.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hidden, encoder_outputs)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mweighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m         \u001b[0mweighted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweighted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [64, 310] but got: [310, 64]."
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "EPOCHS = 10\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in train_dl:\n",
    "        src = batch[0].transpose(1 , 0)\n",
    "        trg = batch[1].transpose(1 , 0)\n",
    "        #trg2 = batch[1].transpose(0 , 1)\n",
    "        print(src.shape,\" :1\")\n",
    "        print(trg.shape,\" :2\")\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        \n",
    "        loss = F.cross_entropy(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    train_loss = round(epoch_loss/ len(train_dl), 3)\n",
    "    \n",
    "    eval_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for batch in val_dl:\n",
    "        src = batch[0].transpose(1, 0)\n",
    "        trg = batch[1].transpose(1, 0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(src, trg)\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[-1].view(-1, output_dim)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "            \n",
    "            loss = F.cross_entropy(output, trg)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "    val_loss = round(eval_loss / len(val_dl), 3)\n",
    "    print(f'Epoch {epoch} | train_loss : {train_loss} | train ppl : {np.exp(train_loss)} | val ppl : {np.exp(val_loss)}')\n",
    "    \n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'nest_model.pt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0, epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in train_dl:\n",
    "        src = batch[0].transpose(0, 1)\n",
    "        trg = batch[1].transpose(0, 1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        \n",
    "        loss = F.cross_entropy(output, trg)\n",
    "        \n",
    "        eval_loss += loss.item()\n",
    "    val_loss = round(eval_loss / len(val_dl), 3)\n",
    "    print(f\"Epoch {epoch} | train loss {train_loss} | train ppl {np.exp(train_loss)} | val ppl {np.exp(val_loss)}\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QofrQ1GAwnDz"
   },
   "source": [
    "# Task 2c. Evaluation on the Test Set (10 pts)\n",
    "Use the trained model to translate the text from the source language into the target language on the test set. Evaluate the performance of the model on the test set using the BLEU metric and print out the average the BLEU score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OJP145YuxAgq"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_brvXpVJxD7e"
   },
   "source": [
    "## Task 3. Improving NMT using Attention (10 pts) \n",
    "Extend the Encoder-Decoder model from Task 2 with the attention mechanism. Retrain the model and evaluate on test set. Print the updated average BLEU score on the test set. In a few sentences explains which model is the best for translation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAOUlKtv0MUn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EncoderGRU(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_vocab_size,  # size of source vocabulary  \n",
    "        hidden_dim,        # hidden dimension of embeddings\n",
    "        encoder_hid_dim,   # gru hidden dim\n",
    "        decoder_hid_dim,   # decoder hidden dim \n",
    "        dropout_prob = .5\n",
    "      ):\n",
    "      \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_vocab_size, hidden_dim)\n",
    "        self.rnn = nn.GRU(hidden_dim, encoder_hid_dim, bidirectional = True)\n",
    "        self.fc = nn.Linear(encoder_hid_dim * 2, decoder_hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "                \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards GRU\n",
    "        #hidden [-1, :, : ] is the last of the backwards GRU\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        enc_hid_dim,      # Encoder hidden dimension\n",
    "        dec_hid_dim       # Decoder hidden dimension \n",
    "      ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention output: [batch size, src len]\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderGRU(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        target_vocab_size,    # Size of target vocab \n",
    "        hidden_dim,           # hidden size of embedding  \n",
    "        enc_hid_dim, \n",
    "        dec_hid_dim, \n",
    "        dropout\n",
    "      ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = target_vocab_size\n",
    "        self.attention = Attention(enc_hid_dim, dec_hid_dim)\n",
    "        \n",
    "        self.embedding = nn.Embedding(target_vocab_size, hidden_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + hidden_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear(\n",
    "            (enc_hid_dim * 2) + dec_hid_dim + hidden_dim, \n",
    "            target_vocab_size\n",
    "          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        input = input.unsqueeze(0)  # [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))  # [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs)     # [batch size, src len]\n",
    "        a = a.unsqueeze(1)                              # [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2) # [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)           # [batch size, 1, enc hid dim * 2]\n",
    "        weighted = weighted.permute(1, 0, 2)               # [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2) # [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]    \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1)) # [batch size, output dim]\n",
    "        return prediction, hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time     \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        \n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):     \n",
    "            #insert input token embedding, previous hidden state and all encoder hidden states\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(preprocess.english_unique_words)\n",
    "OUTPUT_DIM = len(preprocess.irish_unique_words)\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "ENC_HID_DIM = 64\n",
    "DEC_HID_DIM = 64\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "\n",
    "enc = EncoderGRU(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
    "dec = DecoderGRU(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT)\n",
    "\n",
    "model = EncoderDecoder(enc, dec)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "EPOCHS = 5\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "  model.train()\n",
    "  epoch_loss = 0\n",
    "  for batch in tqdm(train_dl):\n",
    "     src = batch[0].transpose(1, 0).to(device)\n",
    "     trg = batch[1].transpose(1, 0).to(device)\n",
    "     optimizer.zero_grad()\n",
    "\n",
    "     output = model(src, trg)\n",
    "\n",
    "     output_dim = output.shape[-1]\n",
    "     output = output[1:].view(-1, output_dim).to(device)\n",
    "     trg = trg[1:].reshape(-1)\n",
    "     \n",
    "     loss = F.cross_entropy(output, trg)\n",
    "     loss.backward()\n",
    "\n",
    "     torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "     optimizer.step()\n",
    "     epoch_loss += loss.item()\n",
    "\n",
    "  train_loss = round(epoch_loss / len(train_dl), 3)\n",
    "  \n",
    "  eval_loss = 0\n",
    "  model.eval()\n",
    "  for batch in tqdm(val_dl):\n",
    "    src = batch[0].transpose(1, 0).to(device)\n",
    "    trg = batch[1].transpose(1, 0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      output = model(src, trg)\n",
    "      \n",
    "      output_dim = output.shape[-1]\n",
    "      output = output[1:].view(-1, output_dim).to(device)\n",
    "      trg = trg[1:].reshape(-1)\n",
    "      \n",
    "      loss = F.cross_entropy(output, trg)\n",
    "      \n",
    "      eval_loss += loss.item()\n",
    "  \n",
    "  val_loss = round(eval_loss / len(val_dl), 3)\n",
    "  print(f\"Epoch {epoch} | train loss {train_loss} | train ppl {np.exp(train_loss)} | val ppl {np.exp(val_loss)}\")\n",
    "\n",
    "\n",
    "  if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    torch.save(model.state_dict(), 'best-model.pt')  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
