{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwuVpgW2v2Zb"
   },
   "source": [
    "# Lab 03 - Transfer Learning w/ DistilBert for Relation Classification\n",
    "\n",
    "In this lab, we'll be working with finetuning Transformer based language model for relation classification. The goals of this lab are the following:\n",
    "- Preparing Data for BERT-based models\n",
    "- Finetuning BERT-based models using HuggingFace Transformers\n",
    "\n",
    "# Data: SemEval 2007 - Task 4: Classification of Semantic Relations Between Nominals\n",
    "\n",
    "Recall from class that relation classification involve identifying the relationship between two or more entities. For example give the following text:\n",
    "```\n",
    "The <e1>artist</e1> made the <e2>picture</e2> when he was a fourth grade student in Iowa City.\n",
    "```\n",
    "What would the semantic relationship between entity 1 `artist` and entity 2 `picture`. Artist produce art and therefore the picture is a product created by the artist. We can label this relationship as `product-producer` where entity 2 is the product and entity 1 is the producer.  \n",
    "\n",
    "The goal of relation classification then is to label the relation between a pair of entities. The [SemEval 2007 - Task 4](https://aclanthology.org/S07-1003/) (Girju et al. 2007) was one the first shared tasks explore relation identification. The associated dataset contains 7 relationships:\n",
    "```\n",
    "cause-effect\n",
    "instrument-agency\n",
    "product-producer\n",
    "origin-entity\n",
    "theme_tool\n",
    "part-whole\n",
    "content-container\n",
    "```\n",
    "\n",
    "In this lab, we'll frame relation-classification as multi-class sequence classification task. Provided a sentence containing two marked entities, the goal is to predict which relation categoy for the entities in the context of the sentence. \n",
    "\n",
    "Run the code below to load the data in memory. The `train`, `val`, and `test` environment variables are dataframes with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9djaqiJqu2Qf",
    "outputId": "2b42f7c7-3e99-434b-be41-c91ef88a13c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-27 11:13:56--  https://raw.githubusercontent.com/dhairyadalal/relation-lab-dataset/main/test.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 81140 (79K) [text/plain]\n",
      "Saving to: ‘test.csv’\n",
      "\n",
      "test.csv            100%[===================>]  79.24K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2023-01-27 11:13:56 (16.0 MB/s) - ‘test.csv’ saved [81140/81140]\n",
      "\n",
      "--2023-01-27 11:13:56--  https://raw.githubusercontent.com/dhairyadalal/relation-lab-dataset/main/train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 127162 (124K) [text/plain]\n",
      "Saving to: ‘train.csv’\n",
      "\n",
      "train.csv           100%[===================>] 124.18K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-01-27 11:13:57 (6.79 MB/s) - ‘train.csv’ saved [127162/127162]\n",
      "\n",
      "--2023-01-27 11:13:57--  https://raw.githubusercontent.com/dhairyadalal/relation-lab-dataset/main/val.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13074 (13K) [text/plain]\n",
      "Saving to: ‘val.csv’\n",
      "\n",
      "val.csv             100%[===================>]  12.77K  --.-KB/s    in 0s      \n",
      "\n",
      "2023-01-27 11:13:57 (80.8 MB/s) - ‘val.csv’ saved [13074/13074]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers >> NULL\n",
    "!wget https://raw.githubusercontent.com/dhairyadalal/relation-lab-dataset/main/test.csv\n",
    "!wget https://raw.githubusercontent.com/dhairyadalal/relation-lab-dataset/main/train.csv\n",
    "!wget https://raw.githubusercontent.com/dhairyadalal/relation-lab-dataset/main/val.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "id": "uLF50GtuvRQ3",
    "outputId": "b65084c7-f1c0-4806-eedc-bbe0f1f68adb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e06a3593-07fd-4d33-a513-d0e8b57ff022\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Most of the &lt;e1&gt;steam&lt;/e1&gt; comes from a volca...</td>\n",
       "      <td>product-producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The &lt;e1&gt;cabin passengers&lt;/e1&gt; composed the &lt;e...</td>\n",
       "      <td>product-producer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Well, this &lt;e1&gt;footballer&lt;/e1&gt; kicked the &lt;e2...</td>\n",
       "      <td>instrument-agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"&lt;e1&gt;Germanium&lt;/e1&gt; is found in &lt;e2&gt;germanite&lt;...</td>\n",
       "      <td>part-whole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Craig expressed his &lt;e1&gt;frustration&lt;/e1&gt; afte...</td>\n",
       "      <td>cause-effect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e06a3593-07fd-4d33-a513-d0e8b57ff022')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e06a3593-07fd-4d33-a513-d0e8b57ff022 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e06a3593-07fd-4d33-a513-d0e8b57ff022');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text              label\n",
       "0  \"Most of the <e1>steam</e1> comes from a volca...   product-producer\n",
       "1  \"The <e1>cabin passengers</e1> composed the <e...   product-producer\n",
       "2  \"Well, this <e1>footballer</e1> kicked the <e2...  instrument-agency\n",
       "3  \"<e1>Germanium</e1> is found in <e2>germanite<...         part-whole\n",
       "4  \"Craig expressed his <e1>frustration</e1> afte...       cause-effect"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "val = pd.read_csv(\"val.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sw88qkZ4xxk6"
   },
   "source": [
    "# Tranfer Learning with Pretrained Neural Language Models\n",
    "Modern language models (BERT, ERNIE, GPT, T5, etc) have been found to be very effective across a wide range of NLP tasks. These models are usually deep neural networds which have been pretrained on large text corpora (i.e. Wikipedia, Common Crawl, BooksCorpus, etc) and are able to learn about the various aspects of language (syntax, grammar, semantics, etc) which can be tranferred acroos various domains and NLP tasks. The Transformer architecture (https://jalammar.github.io/illustrated-transformer/) tends to be the backbone for most modern language models. We sort the transformer models into two categories: autoregressive models and autencoding models. Autoregressive models (e.g. GPT, XLNet) are pretrained on the next word prediction. Given a sequence (the cat sat on the [BLANK]), the model attempts to predict the likely next word the sequence. In contrast autoencoding models (BERT, T5, RoBERTa, ERNIE) are trained to reconstruct corrupted sequences. So a given sentence like the cat sat on the mat would be corrupted by masking a random set of words, e.g. the [MASK] sat on the [MASK], where model must predict the masked tokens. Unlike autoregressive pretraining, the model uses the context of the full input to understand its masked constituent parts. \n",
    "\n",
    "There are two ways to use to these models given an arbitrary task. The weights of the model can be frozen and the last hidden layer output of the model can be used as a set of fixed features. While the method is very quick, it is limited in its efficacy. The other ways is finetuning. Finetuning is the process of updating the pretrained weights in order to adapt the model to a new task and domain (e.g. sentiment classification, relation classification, etc). Since the model already has internalized its own understanding of language, grammar, and semantics, finetuning usually only takes 1-5 epochs of additional gradient updates to condition the model to support the new task. \n",
    "\n",
    "\n",
    "The `HuggingFace Transformers` library hosts implementations and trained weights for nearly all the cutting edge Transformer models and has a unified and easy to use API for finetuning these models. For the final part of the lab we'll walk through how to prepare data for finetuning and train a model for our relation classification task. The `Transformers` library support Pytorch, Tensorflow, and Jax implementation of various models. For this course we'll be using `Pytorch` given is wide-spread adoption in academic research, pythonic paradigm, and ease of debugging with dynamic graph generation. \n",
    "\n",
    "We'll explore finetuning the DistilBERT (https://arxiv.org/abs/1910.01108) model. DistilBERT reduces the size of BERT model (fewer parameters and hidden layers) which allows for quicker finetuning while still retaining 90% of BERT's performance. For all other considerations (input encoding, training, etc) DistilBERT is identical to BERT. We recommend for this section to change your runtime type to GPU as it will dramatically speed up training time. You may find you'll need to rerun earlier cells to ensure the dataset is reloaded into memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4i-Ber411gwr"
   },
   "source": [
    "### Data Preparation\n",
    "\n",
    "In order the prepare the data for BERT finetuning the following steps must be taken:\n",
    "1. Numerically encode string labels and convert to tensor objects\n",
    "2. Encode the text into wordpiece ids, pad inputs, and convert to tensor objects\n",
    "3. Create a Dataset object containing the tensor inputs and labels.\n",
    "\n",
    "### Label Encoding\n",
    "The first thing we need to do is convert our string labels in a numerical representation. The easiest way to enumerate the labels and assign the label the enumerated value.\n",
    "\n",
    "For example \n",
    "```\n",
    "Label                  Encoding\n",
    "---------------       ---------------\n",
    "cause-effect               0\n",
    "content-container          1\n",
    "instrument-agency          2\n",
    "origin-entity              3 \n",
    "part-whole                 4\n",
    "product-producer           5\n",
    "theme_tool                 6\n",
    "``` \n",
    "\n",
    "This can accomplished using the LabelEncoder from the sklearn library. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "ko8wXNtd6Mm1",
    "outputId": "50351f9f-79f3-46e9-f657-dfeb39900178"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7265fe9d-f0b0-4c72-9b45-7ee6ab7d4aa2\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cause-effect</th>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content-container</th>\n",
       "      <th>1</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instrument-agency</th>\n",
       "      <th>2</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin-entity</th>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part-whole</th>\n",
       "      <th>4</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product-producer</th>\n",
       "      <th>5</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theme_tool</th>\n",
       "      <th>6</th>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7265fe9d-f0b0-4c72-9b45-7ee6ab7d4aa2')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7265fe9d-f0b0-4c72-9b45-7ee6ab7d4aa2 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7265fe9d-f0b0-4c72-9b45-7ee6ab7d4aa2');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                 text\n",
       "label             encoded_label      \n",
       "cause-effect      0               126\n",
       "content-container 1               126\n",
       "instrument-agency 2               126\n",
       "origin-entity     3               126\n",
       "part-whole        4               126\n",
       "product-producer  5               126\n",
       "theme_tool        6               126"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load Label Encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# 2. Fit the label encoder to the label in our dataset\n",
    "le.fit(train[\"label\"])\n",
    "\n",
    "# 3. Create a new column with encoded labels\n",
    "train[\"encoded_label\"] = le.transform(train[\"label\"])\n",
    "val[\"encoded_label\"] = le.transform(val[\"label\"])\n",
    "test[\"encoded_label\"] = le.transform(test[\"label\"])\n",
    "\n",
    "# Validate the mapping:\n",
    "train.groupby([\"label\", \"encoded_label\"]).aggregate(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2NQK-iqg7GEy",
    "outputId": "dbfec14b-691b-44ec-e270-d4a95f9fdb1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['content-container', 'part-whole', 'theme_tool'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The label encoder can also be used the tranform ids to labels\n",
    "le.inverse_transform([1,4,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeGluI_JJIfM"
   },
   "source": [
    "Once we've encoded the labels, let's go ahead and convert them to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WiKNzM_TJNhn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_labels = torch.tensor(train[\"encoded_label\"].tolist())\n",
    "val_labels = torch.tensor(val[\"encoded_label\"].tolist())\n",
    "test_labels = torch.tensor(test[\"encoded_label\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaIrX3qt5wq7"
   },
   "source": [
    "### Text Encoding \n",
    "DistilBERT expects wordpiece ids as input. Wordpiece is subword (https://huggingface.co/course/chapter6/6?fw=pt) tokenization algorithm learns a fixed set of token and partial token units which can be used to construct any word. The AutoTokenizer class from can be used to load the BERT wordpiece vocabulary and automatically enocde any text to a sequence of wordpiece ids. Let's explore this a bit further below.\n",
    "\n",
    "The `AutoTokenizer.from_pretrained(model_alias)` method will automatically load the associated tokenizer and vocabulary associated with the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "4f5cd39d2f5846d7908938286170e6ca",
      "cfb2270303c641aaa204e04295d70044",
      "954cbfd4aac84b4197c8a79da48a1d95",
      "65694ce4d98b4238a254976b5b259831",
      "d65fe7a695864d12b6a45118f730009b",
      "bc9b4092ec6e4eab899d6c2de6b1abdf",
      "4bc272219cfe47b09b62097f28bdc56d",
      "e4f0a0110c00437b9694b685441656c4",
      "fdbe59b8afaa4a7f925c4789599138b7",
      "55e3a0f7c1b5405cb5dfccbd779b2436",
      "4709750d83c3447cb89c0eb9abfd8fa6",
      "a692181fcdea4229acfe069f767dd6fb",
      "78580de00bef4531b714346bca0c4dab",
      "9978aec8573e4251b069cb7a5e66c04e",
      "d28ec7fc06154b3d9f77410e0c1d4c92",
      "264e63acbeb04d449ccf08c92f61c5ca",
      "a93bff22100841078445e9d78a685ab1",
      "c420f64edb2540e0a8ffbddb1704e1b5",
      "b2e8eac9f11b462f875d938f88f86d5a",
      "b6db01fc539f4e4299744df6d7812cab",
      "fee1b2b6bb344d49904f2b4ccd9d927b",
      "baa5bd05bc3349a3bca8f950488a4ae9",
      "1cf30c156c1e4f9ba8fb48b43539de8b",
      "dc760efe3e414ec3be40025166b1b18e",
      "78abc761eee64f29b9ad99b3c2dc2ce7",
      "069939536c684d9a8fb3573a86b5da2c",
      "aac1b30fe79a494cb06e65cca877b0d2",
      "0d4e5c67babd472591baced12cda7fbe",
      "8a3b4fb25d874922983414f3f41379ab",
      "301eb817b8d5457c9c4dc21b638605b0",
      "0abeaa3db23247fb8a443fd3644c9686",
      "8d1c7d2d3d2545ed88aae0ce2918b494",
      "7bf93191103846158a4c1a274a4e1749",
      "c840cd7a84e54c7592146a3e95b06b9e",
      "1973ae73776a4f88bcf7ef43e01fde5d",
      "7d3b225ac64e4eafb329ea6f84f5a2cb",
      "56b4d71cb1574341b25618fc37b5fb47",
      "a70de76bc6f646a28a13f9150ed0a852",
      "1724afd781dd4b4ea877bdf07f4f17d9",
      "96adebc758734bb2aee0836c6d0fe593",
      "8133cec154f44925adb1a3a75a96b11d",
      "0a9b7b3694134bfc88550f9dd6a48f30",
      "b695abaa66db42949b15b1f62f214e10",
      "fafdfcfeefb946a1adebe79cc720d6a6"
     ]
    },
    "id": "WOAWqw4mG1za",
    "outputId": "14afa4b0-91b2-46ee-eeef-9f4a6a436f24"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5cd39d2f5846d7908938286170e6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a692181fcdea4229acfe069f767dd6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf30c156c1e4f9ba8fb48b43539de8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c840cd7a84e54c7592146a3e95b06b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIJ_SkwsHZ3l",
    "outputId": "d51ebcb7-e831-4bcc-b245-d84ad48a6b51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer output a dictionary: {'input_ids': [101, 1996, 4248, 2829, 4419, 5598, 2058, 1996, 13971, 3899, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "[CLS] the quick brown fox jumped over the lazy dog. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Encoding a sentence\n",
    "sent = \"The quick brown fox jumped over the lazy dog.\"\n",
    "print(f\"Tokenizer output a dictionary: {tokenizer(sent)}\")\n",
    "\n",
    "# We can also decode ids to vocabulary\n",
    "print(tokenizer.decode([101, 1996, 4248, 2829, 4419, 5598, 2058, 1996, 13971, 3899, 1012, 102]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9gqr8HTHgRS"
   },
   "source": [
    "The `Tokenizer` also handles some useful preprocessing steps for us like padding, truncation, and conversion to pytorch tensors. Most Bert models can handle up 512 tokens, however training a model that large of input tends to be computationally expensive. Since we operating with relatively short sentence, we can set the max_length to about 25 wordpiece tokens. Additionally if we pass all the input texts as once, `Tokenizer` will automatically pad to the specified length. Let try this out on the train dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-c2fWdHINkM"
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(\n",
    "    train[\"text\"].tolist(),\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=24,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tDg4wg9_IzIo"
   },
   "source": [
    "`Tokenizer` will output a dictionary with the input features for training. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JlR8oglI72n",
    "outputId": "c8e33a96-f807-4eba-d075-368202815fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2NbOfG0I-j7",
    "outputId": "6ff03edc-be34-4066-b4b6-2243373b5943"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1000, 2087,  ..., 1026, 1041,  102],\n",
       "        [ 101, 1000, 1996,  ..., 1026, 1013,  102],\n",
       "        [ 101, 1000, 2092,  ..., 3608, 1026,  102],\n",
       "        ...,\n",
       "        [ 101, 1000, 1996,  ..., 1026, 1013,  102],\n",
       "        [ 101, 1000, 2348,  ..., 1013, 1041,  102],\n",
       "        [ 101, 1000, 3402,  ..., 1013, 1041,  102]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bHskl-o5vEyB"
   },
   "outputs": [],
   "source": [
    "val_encodings = tokenizer(\n",
    "    val[\"text\"].tolist(),\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=24,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "test_encodings = tokenizer(\n",
    "    test[\"text\"].tolist(),\n",
    "    padding=True,           # pad all inputs to max length\n",
    "    max_length=24,         # Bert max is 512, we choose 24 for computational efficiency\n",
    "    return_tensors=\"pt\",    # Return format pytorch tensor\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "344BE2as2EoV"
   },
   "source": [
    "Finally we need to create a custom Pytorch Dataset class to store the the generated encodings for our train corpus. The code below creates a custom class and generates the datasets for the train, val, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keCenJlXuQ8q"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define Custom Class for DistilBert Inputs\n",
    "class RelationDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, encodings: dict):  \n",
    "        self.encodings = encodings\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        e = {k: v[idx] for k,v in self.encodings.items()}\n",
    "        return e \n",
    "\n",
    "\n",
    "# Update encodings with labels\n",
    "train_encodings[\"labels\"] = train_labels\n",
    "val_encodings[\"labels\"] = val_labels\n",
    "test_encodings[\"labels\"] = test_labels\n",
    "\n",
    "# Generate Datasets\n",
    "train_ds = RelationDataset(train_encodings)\n",
    "val_ds = RelationDataset(val_encodings)\n",
    "test_ds = RelationDataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhEwZJxKvoS0",
    "outputId": "99f01cfc-2cd0-4864-eb25-5ddd6a1e72f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1000,  2087,  1997,  1996,  1026,  1041,  2487,  1028,  5492,\n",
       "           1026,  1013,  1041,  2487,  1028,  3310,  2013,  1037, 12779,  1005,\n",
       "           1055,  1026,  1041,   102],\n",
       "         [  101,  1000,  1996,  1026,  1041,  2487,  1028,  6644,  5467,  1026,\n",
       "           1013,  1041,  2487,  1028,  3605,  1996,  1026,  1041,  2475,  1028,\n",
       "           7069,  1026,  1013,   102]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([5, 5])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QNilXje2Dai"
   },
   "source": [
    "#Model Training\n",
    "HuggingFace makes it simple to finetune transformer models for any task. First we load the pretrained model. `AutoModelForSequenceClassification` is a generic class combines an language model encoder with a classification head. Next create a `TrainingArgs` object which contains the training configuration details. Finally we create a `Trainer` object which will handle all the requisite training steps (i.e. learning rate scheduling, gradient backprop, etc.\n",
    "\n",
    "Let's first load our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "5ae4ae51751943ea8810f73556e12b12",
      "a4b70028c1ab4699a5132db8e148ac84",
      "44fe96ba9ec248b2a21961207b3d2cc8",
      "dc861334250d4ff8a4fd5cb273eb1418",
      "37c845261ebe484ea7342b5270040639",
      "d80e9de4fe5d4c4c9598243bd8f33f5c",
      "31d03cf8c6c0492b9bd17453f2050576",
      "0acef95dc1894cf69e81842c903ae210",
      "df5586b98b034262a1749c62be1b561a",
      "338892aacfdd4316b4eecdafbce99904",
      "bad109ece7e046be8954b91c6e7421d5"
     ]
    },
    "id": "iv5LttSjumpJ",
    "outputId": "527d9622-72a0-41ca-d6f8-ba4d86117575"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae4ae51751943ea8810f73556e12b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFtgDXakyy7f"
   },
   "source": [
    "### Finetuning Strategies\n",
    "#### Partial Finetuning\n",
    "There several strategies for finetuning. Most Transformer layers have multiple layers. Research shown that those layer often encode various linguistic and semantic information. Though it's difficult to know for certain whats the layers learn, research shows that the higher layers learn general liguistic features and the lower layers (closer to the classification head) pick up task specific information. You can experiment with how many layers you train. \n",
    "\n",
    "Full finetuning involves backpropagating the loss through all the layers in the model. This training strategy tends to be the most effective when adapting for a specific task, but the result models loses the ability to generalize to other tasks. Additionally full finetuning will take longer and require more compute. Partial finetuning involves strategically freezing layers (usually the top layers) and only finetuning the layer closest to the classification head. This tends to be faster and you don't risk losing what the model has learned during pretraining. Let's take a closer look at the model and it's layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsdl4UJGzqer"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jTYZdEczx2j",
    "outputId": "0fb43b09-501c-438e-eb10-abbbbe59c17a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embeddings.weight False\n",
      "position_embeddings.weight False\n",
      "LayerNorm.weight False\n",
      "LayerNorm.bias False\n",
      "0.attention.q_lin.weight True\n",
      "0.attention.q_lin.bias True\n",
      "0.attention.k_lin.weight True\n",
      "0.attention.k_lin.bias True\n",
      "0.attention.v_lin.weight True\n",
      "0.attention.v_lin.bias True\n",
      "0.attention.out_lin.weight True\n",
      "0.attention.out_lin.bias True\n",
      "0.sa_layer_norm.weight True\n",
      "0.sa_layer_norm.bias True\n",
      "0.ffn.lin1.weight True\n",
      "0.ffn.lin1.bias True\n",
      "0.ffn.lin2.weight True\n",
      "0.ffn.lin2.bias True\n",
      "0.output_layer_norm.weight True\n",
      "0.output_layer_norm.bias True\n",
      "1.attention.q_lin.weight False\n",
      "1.attention.q_lin.bias False\n",
      "1.attention.k_lin.weight False\n",
      "1.attention.k_lin.bias False\n",
      "1.attention.v_lin.weight False\n",
      "1.attention.v_lin.bias False\n",
      "1.attention.out_lin.weight False\n",
      "1.attention.out_lin.bias False\n",
      "1.sa_layer_norm.weight False\n",
      "1.sa_layer_norm.bias False\n",
      "1.ffn.lin1.weight False\n",
      "1.ffn.lin1.bias False\n",
      "1.ffn.lin2.weight False\n",
      "1.ffn.lin2.bias False\n",
      "1.output_layer_norm.weight False\n",
      "1.output_layer_norm.bias False\n",
      "2.attention.q_lin.weight False\n",
      "2.attention.q_lin.bias False\n",
      "2.attention.k_lin.weight False\n",
      "2.attention.k_lin.bias False\n",
      "2.attention.v_lin.weight False\n",
      "2.attention.v_lin.bias False\n",
      "2.attention.out_lin.weight False\n",
      "2.attention.out_lin.bias False\n",
      "2.sa_layer_norm.weight False\n",
      "2.sa_layer_norm.bias False\n",
      "2.ffn.lin1.weight False\n",
      "2.ffn.lin1.bias False\n",
      "2.ffn.lin2.weight False\n",
      "2.ffn.lin2.bias False\n",
      "2.output_layer_norm.weight False\n",
      "2.output_layer_norm.bias False\n",
      "3.attention.q_lin.weight False\n",
      "3.attention.q_lin.bias False\n",
      "3.attention.k_lin.weight False\n",
      "3.attention.k_lin.bias False\n",
      "3.attention.v_lin.weight False\n",
      "3.attention.v_lin.bias False\n",
      "3.attention.out_lin.weight False\n",
      "3.attention.out_lin.bias False\n",
      "3.sa_layer_norm.weight False\n",
      "3.sa_layer_norm.bias False\n",
      "3.ffn.lin1.weight False\n",
      "3.ffn.lin1.bias False\n",
      "3.ffn.lin2.weight False\n",
      "3.ffn.lin2.bias False\n",
      "3.output_layer_norm.weight False\n",
      "3.output_layer_norm.bias False\n",
      "4.attention.q_lin.weight False\n",
      "4.attention.q_lin.bias False\n",
      "4.attention.k_lin.weight False\n",
      "4.attention.k_lin.bias False\n",
      "4.attention.v_lin.weight False\n",
      "4.attention.v_lin.bias False\n",
      "4.attention.out_lin.weight False\n",
      "4.attention.out_lin.bias False\n",
      "4.sa_layer_norm.weight False\n",
      "4.sa_layer_norm.bias False\n",
      "4.ffn.lin1.weight False\n",
      "4.ffn.lin1.bias False\n",
      "4.ffn.lin2.weight False\n",
      "4.ffn.lin2.bias False\n",
      "4.output_layer_norm.weight False\n",
      "4.output_layer_norm.bias False\n",
      "5.attention.q_lin.weight True\n",
      "5.attention.q_lin.bias True\n",
      "5.attention.k_lin.weight True\n",
      "5.attention.k_lin.bias True\n",
      "5.attention.v_lin.weight True\n",
      "5.attention.v_lin.bias True\n",
      "5.attention.out_lin.weight True\n",
      "5.attention.out_lin.bias True\n",
      "5.sa_layer_norm.weight True\n",
      "5.sa_layer_norm.bias True\n",
      "5.ffn.lin1.weight True\n",
      "5.ffn.lin1.bias True\n",
      "5.ffn.lin2.weight True\n",
      "5.ffn.lin2.bias True\n",
      "5.output_layer_norm.weight True\n",
      "5.output_layer_norm.bias True\n"
     ]
    }
   ],
   "source": [
    "# Freeze embeddings\n",
    "for name, param in model.distilbert.embeddings.named_parameters():\n",
    "  param.requires_grad = False\n",
    "  print(name, param.requires_grad)\n",
    "\n",
    "# Freeze layers 1-4\n",
    "freeze_layers = [1,2,3,4]\n",
    "for name, param in model.distilbert.transformer.layer.named_parameters():\n",
    "  if int(name[0]) in freeze_layers:\n",
    "    param.requires_grad = False\n",
    "  print(name, param.requires_grad)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie9b8-hKzpbW"
   },
   "source": [
    "#### Training\n",
    "We're finally ready to train the model. To train you need create training arguments object which contains the training details like num_epochs, learning rate scheduling, batch size, etc.\n",
    "\n",
    "The `Trainer` object handles the training loop setup and training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mgccqidtzRv0",
    "outputId": "3c06689a-ca5a-4e8b-c598-270338df001b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 882\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 140\n",
      "  Number of trainable parameters = 14771719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:10, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.717285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.463429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.298611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.226717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.211797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-28\n",
      "Configuration saved in ./results/checkpoint-28/config.json\n",
      "Model weights saved in ./results/checkpoint-28/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-56\n",
      "Configuration saved in ./results/checkpoint-56/config.json\n",
      "Model weights saved in ./results/checkpoint-56/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-84\n",
      "Configuration saved in ./results/checkpoint-84/config.json\n",
      "Model weights saved in ./results/checkpoint-84/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-112\n",
      "Configuration saved in ./results/checkpoint-112/config.json\n",
      "Model weights saved in ./results/checkpoint-112/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-140\n",
      "Configuration saved in ./results/checkpoint-140/config.json\n",
      "Model weights saved in ./results/checkpoint-140/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=1.4396815708705357, metrics={'train_runtime': 10.4162, 'train_samples_per_second': 423.378, 'train_steps_per_second': 13.441, 'total_flos': 27385936794720.0, 'train_loss': 1.4396815708705357, 'epoch': 5.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    lr_scheduler_type='cosine',\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size = 32, \n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfwTyuRYy7iq"
   },
   "source": [
    "### Getting prediction out of the model\n",
    "You can use the predict call `trainer.predict(test_ds)` to run get predictions on the test set. The model will return the logit scores across the label space per prediction. The label with highest logit will be the primary prediction. Using `numpy.argmax` we can get the predicted encoded labels. We'll need to then convert those labels back to string for our classification report.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "UAHquYfW41Fz",
    "outputId": "305ecbec-a841-4f80-9040-0e01a07f324d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 549\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.2292 , -0.501  ,  0.4688 , ...,  0.2272 ,  0.505  , -1.41   ],\n",
      "       [-0.567  , -1.333  , -0.9688 , ...,  0.02377,  0.827  ,  0.01137],\n",
      "       [-1.143  , -0.651  , -0.5312 , ...,  0.3447 ,  0.6216 ,  0.7617 ],\n",
      "       ...,\n",
      "       [ 0.58   , -1.4    , -0.9326 , ..., -0.00762,  0.1239 ,  1.32   ],\n",
      "       [ 2.67   , -1.234  , -0.8555 , ...,  0.2668 , -0.522  , -1.333  ],\n",
      "       [ 0.84   , -1.688  , -0.8203 , ..., -0.3723 ,  0.2014 ,  0.859  ]],\n",
      "      dtype=float16), label_ids=array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), metrics={'test_loss': 1.3803139925003052, 'test_runtime': 0.2807, 'test_samples_per_second': 1955.657, 'test_steps_per_second': 64.12})\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     cause-effect       0.53      0.70      0.61        80\n",
      "content-container       0.66      0.61      0.63        74\n",
      "instrument-agency       0.47      0.50      0.48        78\n",
      "    origin-entity       0.45      0.31      0.36        81\n",
      "       part-whole       0.23      0.11      0.15        72\n",
      " product-producer       0.55      0.43      0.48        93\n",
      "       theme_tool       0.50      0.90      0.64        71\n",
      "\n",
      "         accuracy                           0.50       549\n",
      "        macro avg       0.48      0.51      0.48       549\n",
      "     weighted avg       0.49      0.50      0.48       549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "preds = trainer.predict(test_ds)\n",
    "print(preds)\n",
    "\n",
    "\n",
    "preds = le.inverse_transform(np.argmax(preds.predictions, axis=1))\n",
    "print(classification_report(test[\"label\"].tolist(), preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrSjHlAuy3QL"
   },
   "source": [
    "#### Full Finetuning\n",
    "Let's how the model does if fully finetune it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IdGZr5u65D7r",
    "outputId": "db7f9e90-cf19-448e-f3d7-5dcee77548c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 882\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 140\n",
      "  Number of trainable parameters = 66958855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/140 00:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.569944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.054693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.857287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.806167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.793413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-28\n",
      "Configuration saved in ./results/checkpoint-28/config.json\n",
      "Model weights saved in ./results/checkpoint-28/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-56\n",
      "Configuration saved in ./results/checkpoint-56/config.json\n",
      "Model weights saved in ./results/checkpoint-56/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-84\n",
      "Configuration saved in ./results/checkpoint-84/config.json\n",
      "Model weights saved in ./results/checkpoint-84/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-112\n",
      "Configuration saved in ./results/checkpoint-112/config.json\n",
      "Model weights saved in ./results/checkpoint-112/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 98\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./results/checkpoint-140\n",
      "Configuration saved in ./results/checkpoint-140/config.json\n",
      "Model weights saved in ./results/checkpoint-140/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 549\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.2405 , -1.0205 ,  0.8    , ..., -0.5635 ,  1.097  , -1.455  ],\n",
      "       [-0.739  , -1.103  , -0.3555 , ..., -0.7295 ,  1.516  , -0.7373 ],\n",
      "       [-2.037  ,  0.4438 , -1.092  , ...,  1.587  , -0.304  , -0.05453],\n",
      "       ...,\n",
      "       [ 2.068  , -1.578  , -1.279  , ..., -0.469  ,  0.3857 ,  1.251  ],\n",
      "       [ 3.812  , -0.8027 , -0.703  , ..., -0.2651 , -0.274  , -0.841  ],\n",
      "       [ 3.709  , -0.92   , -0.8037 , ..., -0.3564 ,  0.0277 , -0.5684 ]],\n",
      "      dtype=float16), label_ids=array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
      "       5, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "       4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), metrics={'test_loss': 0.8504007458686829, 'test_runtime': 0.2422, 'test_samples_per_second': 2267.102, 'test_steps_per_second': 74.331})\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "     cause-effect       0.80      0.79      0.79        80\n",
      "content-container       0.74      0.73      0.73        74\n",
      "instrument-agency       0.70      0.71      0.70        78\n",
      "    origin-entity       0.65      0.60      0.63        81\n",
      "       part-whole       0.64      0.62      0.63        72\n",
      " product-producer       0.71      0.73      0.72        93\n",
      "       theme_tool       0.86      0.93      0.89        71\n",
      "\n",
      "         accuracy                           0.73       549\n",
      "        macro avg       0.73      0.73      0.73       549\n",
      "     weighted avg       0.73      0.73      0.73       549\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=7)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    lr_scheduler_type='cosine',\n",
    "    per_device_train_batch_size = 32,\n",
    "    per_device_eval_batch_size = 32, \n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "preds = trainer.predict(test_ds)\n",
    "print(preds)\n",
    "\n",
    "\n",
    "preds = le.inverse_transform(np.argmax(preds.predictions, axis=1))\n",
    "print(classification_report(test[\"label\"].tolist(), preds))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "069939536c684d9a8fb3573a86b5da2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d1c7d2d3d2545ed88aae0ce2918b494",
      "placeholder": "​",
      "style": "IPY_MODEL_7bf93191103846158a4c1a274a4e1749",
      "value": " 232k/232k [00:00&lt;00:00, 746kB/s]"
     }
    },
    "0a9b7b3694134bfc88550f9dd6a48f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0abeaa3db23247fb8a443fd3644c9686": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0acef95dc1894cf69e81842c903ae210": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d4e5c67babd472591baced12cda7fbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1724afd781dd4b4ea877bdf07f4f17d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1973ae73776a4f88bcf7ef43e01fde5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1724afd781dd4b4ea877bdf07f4f17d9",
      "placeholder": "​",
      "style": "IPY_MODEL_96adebc758734bb2aee0836c6d0fe593",
      "value": "Downloading: 100%"
     }
    },
    "1cf30c156c1e4f9ba8fb48b43539de8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dc760efe3e414ec3be40025166b1b18e",
       "IPY_MODEL_78abc761eee64f29b9ad99b3c2dc2ce7",
       "IPY_MODEL_069939536c684d9a8fb3573a86b5da2c"
      ],
      "layout": "IPY_MODEL_aac1b30fe79a494cb06e65cca877b0d2"
     }
    },
    "264e63acbeb04d449ccf08c92f61c5ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "301eb817b8d5457c9c4dc21b638605b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31d03cf8c6c0492b9bd17453f2050576": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "338892aacfdd4316b4eecdafbce99904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37c845261ebe484ea7342b5270040639": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44fe96ba9ec248b2a21961207b3d2cc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0acef95dc1894cf69e81842c903ae210",
      "max": 267967963,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_df5586b98b034262a1749c62be1b561a",
      "value": 267967963
     }
    },
    "4709750d83c3447cb89c0eb9abfd8fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bc272219cfe47b09b62097f28bdc56d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f5cd39d2f5846d7908938286170e6ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfb2270303c641aaa204e04295d70044",
       "IPY_MODEL_954cbfd4aac84b4197c8a79da48a1d95",
       "IPY_MODEL_65694ce4d98b4238a254976b5b259831"
      ],
      "layout": "IPY_MODEL_d65fe7a695864d12b6a45118f730009b"
     }
    },
    "55e3a0f7c1b5405cb5dfccbd779b2436": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56b4d71cb1574341b25618fc37b5fb47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b695abaa66db42949b15b1f62f214e10",
      "placeholder": "​",
      "style": "IPY_MODEL_fafdfcfeefb946a1adebe79cc720d6a6",
      "value": " 466k/466k [00:00&lt;00:00, 649kB/s]"
     }
    },
    "5ae4ae51751943ea8810f73556e12b12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a4b70028c1ab4699a5132db8e148ac84",
       "IPY_MODEL_44fe96ba9ec248b2a21961207b3d2cc8",
       "IPY_MODEL_dc861334250d4ff8a4fd5cb273eb1418"
      ],
      "layout": "IPY_MODEL_37c845261ebe484ea7342b5270040639"
     }
    },
    "65694ce4d98b4238a254976b5b259831": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55e3a0f7c1b5405cb5dfccbd779b2436",
      "placeholder": "​",
      "style": "IPY_MODEL_4709750d83c3447cb89c0eb9abfd8fa6",
      "value": " 28.0/28.0 [00:00&lt;00:00, 1.11kB/s]"
     }
    },
    "78580de00bef4531b714346bca0c4dab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a93bff22100841078445e9d78a685ab1",
      "placeholder": "​",
      "style": "IPY_MODEL_c420f64edb2540e0a8ffbddb1704e1b5",
      "value": "Downloading: 100%"
     }
    },
    "78abc761eee64f29b9ad99b3c2dc2ce7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_301eb817b8d5457c9c4dc21b638605b0",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0abeaa3db23247fb8a443fd3644c9686",
      "value": 231508
     }
    },
    "7bf93191103846158a4c1a274a4e1749": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d3b225ac64e4eafb329ea6f84f5a2cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8133cec154f44925adb1a3a75a96b11d",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0a9b7b3694134bfc88550f9dd6a48f30",
      "value": 466062
     }
    },
    "8133cec154f44925adb1a3a75a96b11d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a3b4fb25d874922983414f3f41379ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d1c7d2d3d2545ed88aae0ce2918b494": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "954cbfd4aac84b4197c8a79da48a1d95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4f0a0110c00437b9694b685441656c4",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fdbe59b8afaa4a7f925c4789599138b7",
      "value": 28
     }
    },
    "96adebc758734bb2aee0836c6d0fe593": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9978aec8573e4251b069cb7a5e66c04e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2e8eac9f11b462f875d938f88f86d5a",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b6db01fc539f4e4299744df6d7812cab",
      "value": 483
     }
    },
    "a4b70028c1ab4699a5132db8e148ac84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d80e9de4fe5d4c4c9598243bd8f33f5c",
      "placeholder": "​",
      "style": "IPY_MODEL_31d03cf8c6c0492b9bd17453f2050576",
      "value": "Downloading: 100%"
     }
    },
    "a692181fcdea4229acfe069f767dd6fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78580de00bef4531b714346bca0c4dab",
       "IPY_MODEL_9978aec8573e4251b069cb7a5e66c04e",
       "IPY_MODEL_d28ec7fc06154b3d9f77410e0c1d4c92"
      ],
      "layout": "IPY_MODEL_264e63acbeb04d449ccf08c92f61c5ca"
     }
    },
    "a70de76bc6f646a28a13f9150ed0a852": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a93bff22100841078445e9d78a685ab1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aac1b30fe79a494cb06e65cca877b0d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2e8eac9f11b462f875d938f88f86d5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b695abaa66db42949b15b1f62f214e10": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6db01fc539f4e4299744df6d7812cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "baa5bd05bc3349a3bca8f950488a4ae9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bad109ece7e046be8954b91c6e7421d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc9b4092ec6e4eab899d6c2de6b1abdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c420f64edb2540e0a8ffbddb1704e1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c840cd7a84e54c7592146a3e95b06b9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1973ae73776a4f88bcf7ef43e01fde5d",
       "IPY_MODEL_7d3b225ac64e4eafb329ea6f84f5a2cb",
       "IPY_MODEL_56b4d71cb1574341b25618fc37b5fb47"
      ],
      "layout": "IPY_MODEL_a70de76bc6f646a28a13f9150ed0a852"
     }
    },
    "cfb2270303c641aaa204e04295d70044": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc9b4092ec6e4eab899d6c2de6b1abdf",
      "placeholder": "​",
      "style": "IPY_MODEL_4bc272219cfe47b09b62097f28bdc56d",
      "value": "Downloading: 100%"
     }
    },
    "d28ec7fc06154b3d9f77410e0c1d4c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fee1b2b6bb344d49904f2b4ccd9d927b",
      "placeholder": "​",
      "style": "IPY_MODEL_baa5bd05bc3349a3bca8f950488a4ae9",
      "value": " 483/483 [00:00&lt;00:00, 33.0kB/s]"
     }
    },
    "d65fe7a695864d12b6a45118f730009b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d80e9de4fe5d4c4c9598243bd8f33f5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc760efe3e414ec3be40025166b1b18e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d4e5c67babd472591baced12cda7fbe",
      "placeholder": "​",
      "style": "IPY_MODEL_8a3b4fb25d874922983414f3f41379ab",
      "value": "Downloading: 100%"
     }
    },
    "dc861334250d4ff8a4fd5cb273eb1418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_338892aacfdd4316b4eecdafbce99904",
      "placeholder": "​",
      "style": "IPY_MODEL_bad109ece7e046be8954b91c6e7421d5",
      "value": " 268M/268M [00:07&lt;00:00, 29.7MB/s]"
     }
    },
    "df5586b98b034262a1749c62be1b561a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4f0a0110c00437b9694b685441656c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fafdfcfeefb946a1adebe79cc720d6a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdbe59b8afaa4a7f925c4789599138b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fee1b2b6bb344d49904f2b4ccd9d927b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
