{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXvmvRi2uyfX",
    "outputId": "c0655186-50a3-47c5-bfcc-16cd67a57fc8"
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HzUzVd6bvjtj"
   },
   "outputs": [],
   "source": [
    "# reading images\n",
    "class ReadData():\n",
    "  def __init__(self, path: str):\n",
    "    self.path = path\n",
    "\n",
    "  def read(self):\n",
    "    images = []\n",
    "    for dirname, _, filenames in os.walk(self.path):\n",
    "      for filename in filenames:\n",
    "          pathname = os.path.join(dirname, filename)\n",
    "          image = Image.open(pathname)\n",
    "\n",
    "\n",
    "          image = image.resize((224, 224))\n",
    "          images.append(np.array(image, dtype = np.int64))\n",
    "\n",
    "    return images\n",
    "\n",
    "alpacaData = ReadData('/dataset/alpaca')\n",
    "\n",
    "notAlpacaData = ReadData('dataset/not alpaca')\n",
    "\n",
    "alpacaImages = alpacaData.read()\n",
    "notAlpacaImages = notAlpacaData.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RckH2LLSxNhU"
   },
   "outputs": [],
   "source": [
    "from keras.backend import normalize_batch_in_training\n",
    "# preprocessing images\n",
    "class PreprocessImages():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def normaliseImages(self, images):\n",
    "        normalisedImages = []\n",
    "        for image in images:\n",
    "            if len(image.shape) != 2:\n",
    "                normalisedImages.append(image/255)\n",
    "        return normalisedImages\n",
    "\n",
    "\"\"\"\n",
    "  def rgbToGray(self, images):\n",
    "    gray_images = []\n",
    "\n",
    "    for image in images:\n",
    "      gray_images.append(cv2.cvtColor(image, cv2.COLOR_RGB2GRAY))\n",
    "    return gray_images\n",
    "\n",
    "\"\"\"\n",
    "preprocessImages = PreprocessImages()\n",
    "normalisedAlpacas = preprocessImages.normaliseImages(alpacaImages)\n",
    "normalisedNotAlpacas = preprocessImages.normaliseImages(notAlpacaImages)\n",
    "#grayImagesAlpacas = preprocessImages.rgbToGray(normalisedAlpacas)\n",
    "#grayImagesNotAlpacas = preprocessImages.rgbToGray(normalisedNotAlpacas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SNr-Z5mi18Sx",
    "outputId": "60d92f3e-21db-413d-823f-792ace10ec99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                images label\n",
      "0    [[[0.6784313725490196, 0.7058823529411765, 0.7...     0\n",
      "1    [[[0.5764705882352941, 0.5254901960784314, 0.4...     0\n",
      "2    [[[0.19607843137254902, 0.21176470588235294, 0...     0\n",
      "3    [[[0.788235294117647, 0.8549019607843137, 0.95...     0\n",
      "4    [[[0.37254901960784315, 0.6431372549019608, 0....     0\n",
      "..                                                 ...   ...\n",
      "178  [[[0.8823529411764706, 0.8901960784313725, 0.9...     0\n",
      "179  [[[0.9529411764705882, 0.984313725490196, 0.98...     0\n",
      "180  [[[0.25098039215686274, 0.18823529411764706, 0...     0\n",
      "181  [[[0.47843137254901963, 0.7647058823529411, 0....     0\n",
      "182  [[[0.7529411764705882, 0.5372549019607843, 0.3...     0\n",
      "\n",
      "[183 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# combining the two class images into one dataset\n",
    "class CreateDataset():\n",
    "    def __self__(self):\n",
    "        pass\n",
    "\n",
    "    def createDataset(self, trueImages, falseImages):\n",
    "        dataset = pd.DataFrame(columns = ['images', 'label'])\n",
    "\n",
    "        for image in trueImages:\n",
    "            dataset.loc[len(dataset), 'images'] = image\n",
    "    \n",
    "        for image in falseImages:\n",
    "            dataset.loc[len(dataset), 'images'] = image\n",
    "\n",
    "            dataset.loc[:len(trueImages)-1, 'label'] = 1\n",
    "            dataset.loc[len(trueImages):, 'label'] = 0\n",
    "        return dataset\n",
    "\n",
    "createDataset = CreateDataset()\n",
    "dataset = createDataset.createDataset(normalisedAlpacas, normalisedNotAlpacas)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iuIOhp9y7Jvn",
    "outputId": "9ad5ea90-3513-4406-d079-ac930c552540"
   },
   "outputs": [],
   "source": [
    "# splitting the dataset into training, validation, and testing\n",
    "trainingData, validationData = train_test_split(dataset,\n",
    "                                             test_size = 0.3,\n",
    "                                             random_state = 110323,\n",
    "                                             stratify = dataset.label)\n",
    "\n",
    "validationData, testingData = train_test_split(validationData,\n",
    "                                             test_size = 0.5,\n",
    "                                             random_state = 110323,\n",
    "                                             stratify = validationData.label)\n",
    "\n",
    "trainingData = trainingData.reset_index().drop(columns=['index'])\n",
    "validationData = validationData.reset_index().drop(columns=['index'])\n",
    "testingData = testingData.reset_index().drop(columns=['index'])\n",
    "print(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5TFauNEIT0WR"
   },
   "outputs": [],
   "source": [
    "class Involution(keras.layers.Layer):\n",
    "  def __init__(self, channel, group_number, kernel_size, stride, reduction_ratio, name):\n",
    "      super().__init__(name=name)\n",
    "\n",
    "      # Initialize the parameters.\n",
    "      self.channel = channel\n",
    "      self.group_number = group_number\n",
    "      self.kernel_size = kernel_size\n",
    "      self.stride = stride\n",
    "      self.reduction_ratio = reduction_ratio\n",
    "\n",
    "  def build(self, input_shape):\n",
    "      # Get the shape of the input.\n",
    "      (_, height, width, num_channels) = input_shape\n",
    "\n",
    "      # Scale the height and width with respect to the strides.\n",
    "      height = height // self.stride\n",
    "      width = width // self.stride\n",
    "\n",
    "      # Define a layer that average pools the input tensor\n",
    "      # if stride is more than 1.\n",
    "      self.stride_layer = (\n",
    "          keras.layers.AveragePooling2D(\n",
    "              pool_size=self.stride, strides=self.stride, padding=\"same\"\n",
    "          )\n",
    "          if self.stride > 1\n",
    "          else tf.identity\n",
    "      )\n",
    "      # Define the kernel generation layer.\n",
    "      self.kernel_gen = keras.Sequential(\n",
    "          [\n",
    "              keras.layers.Conv2D(\n",
    "                  filters=self.channel // self.reduction_ratio, kernel_size=1\n",
    "              ),\n",
    "              keras.layers.BatchNormalization(),\n",
    "              keras.layers.ReLU(),\n",
    "              keras.layers.Conv2D(\n",
    "                  filters=self.kernel_size * self.kernel_size * self.group_number,\n",
    "                  kernel_size=1,\n",
    "              ),\n",
    "          ]\n",
    "      )\n",
    "      # Define reshape layers\n",
    "      self.kernel_reshape = keras.layers.Reshape(\n",
    "          target_shape=(\n",
    "              height,\n",
    "              width,\n",
    "              self.kernel_size * self.kernel_size,\n",
    "              1,\n",
    "              self.group_number,\n",
    "          )\n",
    "      )\n",
    "      self.input_patches_reshape = keras.layers.Reshape(\n",
    "          target_shape=(\n",
    "              height,\n",
    "              width,\n",
    "              self.kernel_size * self.kernel_size,\n",
    "              num_channels // self.group_number,\n",
    "              self.group_number,\n",
    "          )\n",
    "      )\n",
    "      self.output_reshape = keras.layers.Reshape(\n",
    "          target_shape=(height, width, num_channels)\n",
    "      )\n",
    "\n",
    "  def call(self, x):\n",
    "      # Generate the kernel with respect to the input tensor.\n",
    "      # B, H, W, K*K*G\n",
    "      kernel_input = self.stride_layer(x)\n",
    "      kernel = self.kernel_gen(kernel_input)\n",
    "\n",
    "      # reshape the kerenl\n",
    "      # B, H, W, K*K, 1, G\n",
    "      kernel = self.kernel_reshape(kernel)\n",
    "\n",
    "      # Extract input patches.\n",
    "      # B, H, W, K*K*C\n",
    "      input_patches = tf.image.extract_patches(\n",
    "          images=x,\n",
    "          sizes=[1, self.kernel_size, self.kernel_size, 1],\n",
    "          strides=[1, self.stride, self.stride, 1],\n",
    "          rates=[1, 1, 1, 1],\n",
    "          padding=\"SAME\",\n",
    "      )\n",
    "\n",
    "      # Reshape the input patches to align with later operations.\n",
    "      # B, H, W, K*K, C//G, G\n",
    "      input_patches = self.input_patches_reshape(input_patches)\n",
    "\n",
    "      # Compute the multiply-add operation of kernels and patches.\n",
    "      # B, H, W, K*K, C//G, G\n",
    "      output = tf.multiply(kernel, input_patches)\n",
    "      # B, H, W, C//G, G\n",
    "      output = tf.reduce_sum(output, axis=3)\n",
    "\n",
    "      # Reshape the output kernel.\n",
    "      # B, H, W, C\n",
    "      output = self.output_reshape(output)\n",
    "\n",
    "      # Return the output tensor and the kernel.\n",
    "      return output, kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM4zLzzwh01d"
   },
   "outputs": [],
   "source": [
    "X_train = np.array([t for t in trainingData['images']])\n",
    "y_train = np.array([int(t) for t in trainingData['label']])\n",
    "X_val = np.array([t for t in validationData['images']])\n",
    "y_val = np.array([int(t) for t in validationData['label']])\n",
    "X_test = np.array([t for t in testingData['images']])\n",
    "y_test = np.array([int(t) for t in testingData['label']])\n",
    "\n",
    "assert(len(X_train) == len(y_train))\n",
    "assert(len(X_val) == len(y_val))\n",
    "assert(len(X_test) == len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SIS5zmUMnAzF",
    "outputId": "c6ed69f6-e043-4949-cef7-7196ecafd98e"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import accuracy\n",
    "\n",
    "# Build the involution model.\n",
    "print(\"building the involution model...\")\n",
    "\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x, _ = Involution(channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_1\")(inputs)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x, _ = Involution(channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_2\")(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x, _ = Involution(channel=3, group_number=1, kernel_size=3, stride=1, reduction_ratio=2, name=\"inv_3\")(x)\n",
    "x = keras.layers.ReLU()(x)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(10, activation=\"relu\")(x)\n",
    "\n",
    "\n",
    "\n",
    "outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "inv_model = keras.Model(inputs=[inputs], outputs=[outputs], name=\"inv_model\")\n",
    "\n",
    "inv_model.compile(optimizer =  keras.optimizers.Adam(0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics = [\"accuracy\"])\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-g6WAlgRo5kd",
    "outputId": "d6ee54b6-5e27-4473-eba1-a409ffdf299f"
   },
   "outputs": [],
   "source": [
    "inv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "id": "Y2bE7WyWtew8",
    "outputId": "4651c7cb-5fbc-4314-fd43-ff61b9e05f21"
   },
   "outputs": [],
   "source": [
    "inv_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llGGjGTXuQ5B"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = inv_model.predict(X_test)\n",
    "accuracy_score(y_test, np.round(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpxGanTQwFp8"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "\n",
    "cnn = Sequential()\n",
    "\n",
    "cnn.add(Conv2D(16, kernel_size=(3,3), activation='relu', input_shape=(224, 224, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(12, kernel_size=(3,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Conv2D(8, kernel_size=(3,3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(256, activation='relu'))\n",
    "cnn.add(Dense(1))\n",
    "cnn.add(Activation(activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "cnn.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate = 0.001), metrics=['accuracy'])\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "Ijcxk0PJvQ_f",
    "outputId": "ec9a7991-c762-44c4-e7b0-c65f70cd4fbc"
   },
   "outputs": [],
   "source": [
    "cnn.fit(X_train, y_train, validation_data=(X_val, y_val), epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1S6BbJmvV-X"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = cnn.predict(X_test)\n",
    "accuracy_score(y_test, np.round(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-H6LihBy50-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
