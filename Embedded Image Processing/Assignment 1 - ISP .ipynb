{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf518bcf",
   "metadata": {},
   "source": [
    "# EE551 Embedded Image Processing\n",
    "## Assignment 1 - Image Signal Processor (ISP)\n",
    "\n",
    "### Background\n",
    "An ISP is a processing block that converts raw sensor images into a colour array. There is a surprising amount of image processing that occurs between image capture and output colour images. In this assignment, you will implement a basic ISP.\n",
    "\n",
    "You will be provided with samples of binary files containing raw sensor images (details of how to read these image files will be provided). The task is then to convert this raw data into a colour image.\n",
    "\n",
    "The following processing will be done:\n",
    "- Read in the image\n",
    "- Demosaic (convert raw to RGB)\n",
    "- Apply Colour Correction Matrix (matrix will be provided)\n",
    "- Apply Denoise (e.g. bilateral filter)\n",
    "- Apply Edge Enhancement (e.g. unsharp mask)\n",
    "- Apply Contrast Enhancement (e.g. CLAHE)\n",
    "- Save result to an output file\n",
    "\n",
    "## Submission Details\n",
    "Assignment deadline: Midnight, Friday 10th Feb \\\n",
    "Jupyter Notebook containing submission to be submitted via blackboard \\\n",
    "Total grade: 10% of final module mark \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afb5df",
   "metadata": {},
   "source": [
    "# Submission details:\n",
    "#### Name:\n",
    "#### ID:\n",
    "#### Class code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa99dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement cv2 (from versions: none)\n",
      "ERROR: No matching distribution found for cv2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19384/904170686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexposure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Useful libraries\n",
    "!pip install cv2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage import exposure\n",
    "from scipy import ndimage\n",
    "import matplotlib.pylab as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dda3e6a",
   "metadata": {},
   "source": [
    "## Read in the raw image file\n",
    "\n",
    "For this assignment, a raw image file will be provided. This is an image of a photographic test target. The pixel data\n",
    "is stored as unsigned integers, 8 bits per pixel. The code for reading the image will be provided.\n",
    "\n",
    "The general process is to read in the binary information, then reshape the array into the image dimensions (in this case, 4096*2160 pixels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49ab1d05",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19384/3853859637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# plot the resulting raw file inline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Read in the file\n",
    "\n",
    "# Raw file details:\n",
    "# width - 4096\n",
    "# height - 2160\n",
    "# bit depth - 8\n",
    "# Bayer pattern - rggb\n",
    "\n",
    "\n",
    "bayer_width = 4096\n",
    "bayer_height = 2160\n",
    "\n",
    "raw_path = 'chart.raw'\n",
    "\n",
    "bayer = np.fromfile(raw_path, dtype='uint8', sep='')\n",
    "\n",
    "bayer = bayer.reshape((bayer_height, bayer_width))\n",
    "\n",
    "# plot the resulting raw file inline\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(bayer,cmap=plt.get_cmap('gray'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90f09ea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19384/1580212694.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# plot the resulting raw file inline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbayer_crop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# crop and show a small area, to show the Bayer raw pattern\n",
    "\n",
    "bayer_crop = bayer[600:900, 600:900] \n",
    "\n",
    "# plot the resulting raw file inline\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(bayer_crop,cmap=plt.get_cmap('gray'))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05597b1d",
   "metadata": {},
   "source": [
    "## Demosaic the image\n",
    "The demosaic process converts raw pixel data into RGB image data. Each raw sensor pixel contains only one colour. Part of the demosaic process is to use interpolation to generate the missing colours for each pixel (i.e. a red pixel will get green and blue pixel information from the neighbouring pixels\n",
    "\n",
    "Hint: use the opencv \"cvtColor\" function. This function can be used to convert between many colour spaces. For this assignment, you'll want the \"COLOR_BAYER_RG2BGR\" option. \n",
    "\n",
    "more general details are available here: https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49cf4e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demosaic the image (i.e. covert from raw image to RGB)\n",
    "\n",
    "\n",
    "# plot the resulting raw file inline\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "175258a7",
   "metadata": {},
   "source": [
    "## Apply colour correction\n",
    "\n",
    "A colour correction matrix is applied to improve colour reproduction accuracy. If you notice, red appears too orange before\n",
    "correction is applied.\n",
    "\n",
    "The colour correction matrix (CCM) is calculated during the camera development phase, and varies from camera to camera.\n",
    "\n",
    "For simplicity, the CCM for this particular camera is provided below:\n",
    "    \n",
    "    [[ 1382, -113, -246], [ -484, 1808, -300], [ 102, -860, 1802]]\n",
    "    \n",
    " \n",
    " This 3*3 matrix is multiplied by the RGB values for every pixel\n",
    " \n",
    " ![image.png](attachment:image.png)\n",
    " \n",
    " \n",
    " \n",
    " Note that for embedded applications, floating point numbers are avoided wherever possible. In this example, the base is 1024 (i.e. to convert to floating point, divide the CCM by 1024)\n",
    " \n",
    " To apply the CCM in this example, the following steps are required:\n",
    " - cast the image to np.int32\n",
    " - multiply the RGB pixel data by the 3*3 CCM\n",
    " - divide by 1024\n",
    " - re-cast the image back to np.uint8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ddb57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply colour correction matrix\n",
    "# note: to avoid clipping, we have to temporarily cast our image data to uint16, and then return to 8 bit\n",
    "\n",
    "# hint - cast the ccm array and image as np.int32\n",
    "# multiply the image by the ccm matrix, and then use np.right_shift to scale the image down to the 8 bit range again\n",
    "# use the np.clip function to ensure the data range is within 0 and 255\n",
    "\n",
    "ccm = np.array([[ 1382, -113, -246], [ -484, 1808, -300], [ 102, -860, 1802]],dtype=np.int32).T\n",
    "\n",
    "# plot the resulting raw file inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021016df",
   "metadata": {},
   "source": [
    "## Apply gamma correction\n",
    "\n",
    "Gamma correction is applied using the following formula:\n",
    "\n",
    "$$\n",
    "outputImage = ((inputImage / 255)^\\gamma) * 255\n",
    "$$\n",
    "\n",
    "Typically, $$\\gamma=1/2.2$$\n",
    "\n",
    "\n",
    "hint - use numpy clip function to ensure the data range is within 0 and 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d576f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply gamma correction\n",
    "\n",
    "# plot the resulting raw file inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e543c2e1",
   "metadata": {},
   "source": [
    "## Apply denoise to image\n",
    "\n",
    "For this block, it is up to the student to decide which denoise block to use (there are several options available). \n",
    "\n",
    "One good option would be openCV's bilateral filter\n",
    "\n",
    "Hint - experiment with parameters, examine the effect of different parameters on the image. There isn't necessarily a right or wrong configuration, but changing the parameters will have an impact on the final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9fac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply image denoise filtering (bilateral filter)\n",
    "# hint - use opencv cv2.bilateral filter\n",
    "\n",
    "# experiment with filter coefficients to see the impact on the image. It might help to crop on an area to get the full effect\n",
    "\n",
    "\n",
    "# plot the resulting raw file inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57fea88",
   "metadata": {},
   "source": [
    "## Apply edge enhancement\n",
    "\n",
    "Apply edge enhancement to the image. Again, it is up to the student to select the edge enhancement approach used (we covered a few options in class)\n",
    "\n",
    "Again, vary the parameters and see the impact on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c921955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply edge enhancement\n",
    "# hint: implement Laplacian or unsharp mask filtering from previous course material. \n",
    "\n",
    "\n",
    "\n",
    "# plot the resulting raw file inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898cd4e",
   "metadata": {},
   "source": [
    "## Apply contrast enhancement\n",
    "\n",
    "Finally, apply contrast enhancement to the image. It is up to the student to select the contrast enhancement used. One option would be adaptive histogram equalization, covered earlier in the module (check out the skimage exposure library). And again, vary the parameters to examine the effect on the final image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e733e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase image contrast. Hint - check out skimage exposure\n",
    "\n",
    "# plot the resulting raw file inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d7a07e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
