{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJY7QD40vrm-"
   },
   "source": [
    "# Exercise 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJYUWq73vsk2"
   },
   "source": [
    "The motivation of this exercise is to gain familiarity with the Python programming language. We are going to do some basic text processing and analysis on a plaintext corpus. If you are not with familiar Python or Jupyter notebooks, it is recommended to start with the Python Tutorial notebook before attempting this exercise.\n",
    "\n",
    "---\n",
    "\n",
    "For this exercise, we are going to count the 25 most frequent words in **Alice’s Adventures in Wonderland** by Lewis Carroll. You are free to use any other piece of text of your choice for this exercise. This notebook contains step by step instructions (with some hints) and you are required to fill in the code blocks based on the material covered in the Python Tutorial notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T48PL4payl55"
   },
   "source": [
    "### 0. Download the text file.\n",
    "Run the cell below to download the book **Alice’s Adventures in Wonderland** as a text file from [Project Gutenberg](http://www.gutenberg.org), and save into a file called `alice.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nW1cmwsAfXh9",
    "outputId": "a8b7ad0d-b8b3-43b3-a3c6-a246a0f3c6de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100  170k  100  170k    0     0  1057k      0 --:--:-- --:--:-- --:--:-- 1057k\n"
     ]
    }
   ],
   "source": [
    "!curl https://www.gutenberg.org/files/11/11-0.txt > alice.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSRMWLlFfp22"
   },
   "source": [
    "---\n",
    "### 1. Read text from file.\n",
    "Open the text file `alice.txt` and read all the lines into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QOshGZfAfhA1"
   },
   "outputs": [],
   "source": [
    "lines = []  # read lines from alice.txt into this list\n",
    "with open('alice.txt', 'r', encoding='utf-8') as f:\n",
    "  lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW_0RVZpFijM"
   },
   "outputs": [],
   "source": [
    "# another way to do it \n",
    "f = open('alice.txt', 'r', encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt9qAKiVhH2m"
   },
   "source": [
    "---\n",
    "### 2. Filter out the metadata.\n",
    "The text file contains some metadata about the book which is not relevant for our analysis. Discard this information by removing the first 54 lines from the beginning and the last 356 lines from the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwnNTTxUhFkE"
   },
   "outputs": [],
   "source": [
    "lines = lines[54:-356]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48rOMHm3Mbdy",
    "outputId": "73f57d8b-6b7e-4d44-ec00-983cf1f71875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I.\n",
      "\n",
      "THE END \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines[0])\n",
    "print(lines[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTvlIw-whuwy"
   },
   "source": [
    "---\n",
    "### 3. Remove leading and trailing spaces from each line in the list.\n",
    "Each line contains a newline character `\\n` at the end while some lines also contain leading and trailing spaces. This formatting is done for presentation purposes and not relevant for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYdh18lHgsj0"
   },
   "outputs": [],
   "source": [
    "clean_lines = []  # store the lines in this list after removing the leading and trailing spaces\n",
    "for line in lines:\n",
    "  clean_lines.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSu406W9iqMo"
   },
   "source": [
    "---\n",
    "### 4. Remove empty lines from the list.\n",
    "After removing the newline character `\\n` from each line in the list, some strings are now empty and can be discarded safely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1djnrvHh2kc"
   },
   "outputs": [],
   "source": [
    "non_empty_lines = []  # store non empty lines in this list\n",
    "for line in clean_lines:\n",
    "  if line != '':\n",
    "    non_empty_lines.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNCnBgL-jNe1"
   },
   "source": [
    "---\n",
    "### 5. Join all the non empty lines into a single string.\n",
    "Now that we have cleaned the corpus by removing some editorial details and formatting, we can focus on the actual text. Create a single string which contains all the lines from the text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iED8UQpciCv7"
   },
   "outputs": [],
   "source": [
    "text = ' '.join(non_empty_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vxri7Uw_keFd"
   },
   "source": [
    "---\n",
    "### 6. Convert to lowercase\n",
    "To keep the word counts consistent, we are going to covert everything lowercase. If we don't do this, the words `the`, `The` and `THE` would be considered distinct.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dy8tLkbqj2mw"
   },
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6jvhDdJki-_"
   },
   "source": [
    "---\n",
    "### 7. Get a list of all the words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyYdI8rrkfLL",
    "outputId": "c8160db6-6b8d-4ae1-9932-768b103e6082"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'had',\n",
       " 'no',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversations',\n",
       " 'in',\n",
       " 'it,',\n",
       " '“and',\n",
       " 'what']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text.split(' ')\n",
    "words[40:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTiG6FrDN4sP"
   },
   "source": [
    "### 8. Remove punctuation\n",
    "\n",
    "For a machine, character sequences `rabbit`, `rabbit,` and `rabbit!` are diferrent words, although we as humans understand that this is the same word with/without punctuation marks after it. To avoid this confusion, we can remove punctuation, because it is unnecessary for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AIX-jLblN1TI",
    "outputId": "468d554a-82ef-4d4b-c743-170104df20ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'had',\n",
       " 'no',\n",
       " 'pictures',\n",
       " 'or',\n",
       " 'conversations',\n",
       " 'in',\n",
       " 'it',\n",
       " 'and',\n",
       " 'what']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct = '.,?!:;—\"«»()[]{}–~*@#$^&\\/„“‘’-|+=`'\n",
    "new_words = [w.strip(punct) for w in words] # this is a list comprehension\n",
    "new_words = [w for w in words if w not in punct]\n",
    "new_words[40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_O07bDJrM8Ss"
   },
   "outputs": [],
   "source": [
    "# this \n",
    "words = [w.strip(punct) for w in words]\n",
    "\n",
    "# equals this\n",
    "new_words = []\n",
    "for w in words:\n",
    "    new_words.append(w.strip(punct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ID09CxSky1g"
   },
   "source": [
    "---\n",
    "### 9. How many total words are there in the text?\n",
    "\n",
    "Individuals elements in a text (usually words, but not only) are called **tokens** in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8UY3Em8kpRb",
    "outputId": "c8e934b7-c333-4b42-f2d0-38a419b8490b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26381"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ome93kmzk2tU"
   },
   "source": [
    "---\n",
    "### 10. How many unique words are there in the text?\n",
    "\n",
    "Unique words are also called **types** in NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C2rJYlgekqkL",
    "outputId": "f760eba4-3995-4a80-aa36-737d04d337c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnSpE4-elByQ"
   },
   "source": [
    "---\n",
    "### 11. What are the 25 most frequent words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V62gHcL1ufqK",
    "outputId": "7162b1c3-1252-4fb0-cabe-ea8743930309"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1629),\n",
       " ('and', 843),\n",
       " ('to', 715),\n",
       " ('a', 626),\n",
       " ('she', 534),\n",
       " ('of', 505),\n",
       " ('it', 477),\n",
       " ('said', 456),\n",
       " ('alice', 383),\n",
       " ('i', 380),\n",
       " ('in', 360),\n",
       " ('was', 347),\n",
       " ('you', 329),\n",
       " ('as', 262),\n",
       " ('her', 246),\n",
       " ('that', 240),\n",
       " ('at', 208),\n",
       " ('on', 183),\n",
       " ('had', 177),\n",
       " ('with', 176),\n",
       " ('all', 169),\n",
       " ('but', 164),\n",
       " ('for', 149),\n",
       " ('so', 145),\n",
       " ('be', 139)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = dict()    # create an empty dictionary for word counts\n",
    "for word in words:\n",
    "  if word in word_counts:\n",
    "    word_counts[word] += 1\n",
    "  else:\n",
    "    word_counts[word] = 1\n",
    "\n",
    "word_counts = list(word_counts.items())  # convert dict to a list of tuples for word counts\n",
    "sorted_by_word_counts = sorted(word_counts, key=lambda x: x[1], reverse=True)\n",
    "sorted_by_word_counts[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I8RGDU2uj6V"
   },
   "source": [
    "#### Alternate Solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWuhpqKsvNOg"
   },
   "source": [
    "1. Python >= 3.6 supports ordered dictionaries, so there is no need to convert to a list of tuples before sorting.\n",
    "2. Look up the `Counter` container in the `collections` module in the [Python docs](https://docs.python.org/3/library/collections.html#collections.Counter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYhHclDCpfKS",
    "outputId": "36750724-5407-4cf9-f790-108ba11e5a7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1629),\n",
       " ('and', 843),\n",
       " ('to', 715),\n",
       " ('a', 626),\n",
       " ('she', 534),\n",
       " ('of', 505),\n",
       " ('it', 477),\n",
       " ('said', 456),\n",
       " ('alice', 383),\n",
       " ('i', 380),\n",
       " ('in', 360),\n",
       " ('was', 347),\n",
       " ('you', 329),\n",
       " ('as', 262),\n",
       " ('her', 246),\n",
       " ('that', 240),\n",
       " ('at', 208),\n",
       " ('on', 183),\n",
       " ('had', 177),\n",
       " ('with', 176),\n",
       " ('all', 169),\n",
       " ('but', 164),\n",
       " ('for', 149),\n",
       " ('so', 145),\n",
       " ('be', 139)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter(words)\n",
    "word_counts.most_common(25)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6I8RGDU2uj6V"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
