{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT8Fekl4ewqq"
      },
      "source": [
        "# Learning Objectives\n",
        "\n",
        "In this lab we are going to:\n",
        "\n",
        "*   Explore POS Tagging using NLTK\n",
        "*   Learn about Hidden Markov Models (HMM)\n",
        "*   Perform POS tagging with HMM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQM_Wv2AHOJ",
        "outputId": "d83eb17a-217a-4109-93e5-0096dd6500f2"
      },
      "source": [
        "# Installing necessary packages from NLTK\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLh8csmUf0-l"
      },
      "source": [
        "# POS Tagging \n",
        "POS tagging is the process of assigning a part-of-speech label to\n",
        "each word in an input text, where the tagging model takes a sequence of words and a tagset as input and gives the output as a sequence of tags one per token. There are various parts of speech tagsets. The most common tagsets are:\n",
        "\n",
        "1- <a href= \"http://ucrel.lancs.ac.uk/claws5tags.html\">Claws5</a>: 62 different tags <br>\n",
        "2- <a href=\"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\">Penn Treebank</a>: 45 different tags <br>\n",
        "3- <a href = \"https://en.wikipedia.org/wiki/Brown_Corpus\">The Brown Corpus tagset</a>: (87 tags)<br>\n",
        "4- <a href = \"https://universaldependencies.org/u/pos/\">UD tagset</a>\n",
        "\n",
        "## Approaches\n",
        "\n",
        "POS tagging can be done using different approaches such as:\n",
        " \n",
        "\n",
        "*   Pointwise prediction: a classifier that predicts each word individually such as perceptron.\n",
        "\n",
        "*   Generative sequence models: a probabilistic model that assigns probabilities to sequences of words such as Hidden Markov Model.\n",
        "\n",
        "\n",
        "*   Discriminative sequence models: predict whole sequence with a classifier such as conditional random fields (CRF)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyOu22_if9Pp"
      },
      "source": [
        "\n",
        "# NLTK POS Tagging\n",
        "\n",
        "The NLTK tagger can be used as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTylIk5df8NL",
        "outputId": "a377f166-ce6d-4c52-ba4b-c2cfe1a88399"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# tokenize the sentence before POS tagging\n",
        "text = word_tokenize(\"And is it very interesting for everyone?\")\n",
        "nltk.pos_tag(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('And', 'CC'),\n",
              " ('is', 'VBZ'),\n",
              " ('it', 'PRP'),\n",
              " ('very', 'RB'),\n",
              " ('interesting', 'VBG'),\n",
              " ('for', 'IN'),\n",
              " ('everyone', 'NN'),\n",
              " ('?', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36eoGYFcg4bm"
      },
      "source": [
        "The brown corpus has been manually tagged with part-of-speech tags which is useful for testing taggers and for training statistical taggers. In order to read a tagged corpus we can use:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K254qLzRg677",
        "outputId": "9498f10e-2736-4757-bb23-3800ad1e7670"
      },
      "source": [
        "from nltk.corpus import brown\n",
        "# Accessing manually tagged brown corpus\n",
        "print (brown.tagged_words())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'AT'), ('Fulton', 'NP-TL'), ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsOFmUxf_--e"
      },
      "source": [
        "## Exercise 1:\n",
        "Get the count of each POS tag assigned to the word **(ignore case)** \"_dog_\" in the **news** category of the Brown corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSP62tgn_nVy",
        "outputId": "212dd8be-e5c8-4c6d-9c84-b31e6eedca58"
      },
      "source": [
        "# Slicing brown corpus with news category\n",
        "tagged_words = brown.tagged_words(categories='news')\n",
        "tag_count_map = {}\n",
        "\n",
        "# get frequency\n",
        "for word,tag in tagged_words:\n",
        "    # checking if \"dog\" is tagged in the brown corpus\n",
        "    if word.lower() == \"dog\":\n",
        "        if tag in tag_count_map.keys():\n",
        "            tag_count_map[tag] = tag_count_map[tag] + 1 # increasing the count by 1 if the tag is already present\n",
        "        else:\n",
        "            tag_count_map[tag] = 1 # adding new entry in the dictionary\n",
        "# print\n",
        "tag_count_map"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NN': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "devDkPSCjHGU",
        "outputId": "e12d12a0-b941-4ef5-aa19-711dc6d28a0b"
      },
      "source": [
        "# one-liner implementation using Counter and list comprehension\n",
        "from collections import Counter\n",
        "Counter([tag for (word, tag) in brown.tagged_words(categories=['news']) if word.lower() == 'dog'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'NN': 7})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U_MiY1LjOI6",
        "outputId": "9fa79a3a-1c97-40d5-9f21-93b36679250c"
      },
      "source": [
        "# using ConditionalFreqDist in nltk\n",
        "tagged_words = brown.tagged_words(categories=['news'])\n",
        "# lower case 'dog'\n",
        "tagged_words = [(word.lower(), tag) for (word, tag) in tagged_words]\n",
        "# use cond. freq. dist. given the tag\n",
        "cfd = nltk.ConditionalFreqDist(tagged_words)\n",
        "cfd['dog']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'NN': 7})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh3S-fbyAzcl"
      },
      "source": [
        "## Exercise 2:\n",
        "Find the frequency distribution of each tag in the brown corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdKTPHucV-7f",
        "outputId": "f0a0908c-640e-4759-a661-e92e5a8f2f01"
      },
      "source": [
        "tagged_words = brown.tagged_words()\n",
        "counts = dict()\n",
        "\n",
        "for word, tag in tagged_words:\n",
        "  if tag in counts:\n",
        "    counts[tag] += 1\n",
        "  else:\n",
        "    counts[tag] = 1\n",
        "\n",
        "sorted_counts = sorted(counts.items(), key=lambda c: c[1], reverse=True)\n",
        "sorted_counts[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NN', 152470), ('IN', 120557), ('AT', 97959), ('JJ', 64028), ('.', 60638)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVlYhQe1jeXa",
        "outputId": "866b4431-e819-47dd-9107-487bf2738ad7"
      },
      "source": [
        "# using Counter and map\n",
        "Counter(map(lambda x: x[1], brown.tagged_words())).most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NN', 152470), ('IN', 120557), ('AT', 97959), ('JJ', 64028), ('.', 60638)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZxgSKDMjgxD",
        "outputId": "5079299e-c731-4b6f-a5ab-2cfa523b1763"
      },
      "source": [
        "# using FreqDist in nltk\n",
        "tagged_words = brown.tagged_words()\n",
        "words, tags = zip(*tagged_words)\n",
        "freq_dist = nltk.FreqDist(tags)\n",
        "freq_dist.most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('NN', 152470), ('IN', 120557), ('AT', 97959), ('JJ', 64028), ('.', 60638)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSEIc7EAjYEq"
      },
      "source": [
        "## Exercise 3:\n",
        "\n",
        "What are the most common verbs in **fiction** category in the brown corpus? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0y6erNBBB-h",
        "outputId": "8fc5ef96-8fdc-4d72-b80b-f78df26b4fd6"
      },
      "source": [
        "# your code goes here;\n",
        "\n",
        "verb_tags = ['VB', 'VBN', 'VBD', 'VBG', 'VBZ']\n",
        "tagged_words = brown.tagged_words(categories=['fiction'])\n",
        "counts = dict()\n",
        "\n",
        "for word, tag in tagged_words:\n",
        "  if tag in verb_tags:\n",
        "    if (word, tag) in counts:\n",
        "      counts[(word, tag)] += 1\n",
        "    else:\n",
        "      counts[(word, tag)] = 1\n",
        "\n",
        "sorted_counts = sorted(counts.items(), key=lambda c: c[1], reverse=True)\n",
        "sorted_counts[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('said', 'VBD'), 177),\n",
              " (('came', 'VBD'), 91),\n",
              " (('went', 'VBD'), 79),\n",
              " (('get', 'VB'), 78),\n",
              " (('know', 'VB'), 74)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqersUCWjosU",
        "outputId": "88b97e8e-fe7e-40b2-c9e1-f9c1beb8f24b"
      },
      "source": [
        "# one-liner using Counter and list comprehension\n",
        "Counter([(word, tag) for (word, tag) in brown.tagged_words(categories=['fiction']) if tag.startswith('VB')]).most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('said', 'VBD'), 177),\n",
              " (('came', 'VBD'), 91),\n",
              " (('went', 'VBD'), 79),\n",
              " (('get', 'VB'), 78),\n",
              " (('know', 'VB'), 74)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM2RGcpejqle",
        "outputId": "5bf70ac8-060a-4df9-a942-8a48e600ddfa"
      },
      "source": [
        "# using FreqDist in nltk\n",
        "fiction_tagged_words = brown.tagged_words(categories='fiction')\n",
        "fiction_tagged_words = [(word, tag) for (word, tag) in fiction_tagged_words if tag.startswith('VB')]\n",
        "freq_dist = nltk.FreqDist(fiction_tagged_words)\n",
        "freq_dist.most_common(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('said', 'VBD'), 177),\n",
              " (('came', 'VBD'), 91),\n",
              " (('went', 'VBD'), 79),\n",
              " (('get', 'VB'), 78),\n",
              " (('know', 'VB'), 74)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzr1U3OLhlzW"
      },
      "source": [
        "# Hidden Markov Model\n",
        "\n",
        "The sequence of tags can be viewed as a Markov chain so let us explore the construction and solution of a Hidden Markov Model. \n",
        "\n",
        "An HMM has two components:\n",
        "\n",
        "*   **Transition Probabilities** which represents the probability of a tag occurring given the previous tag i.e. $P(t_i|t_{i-1})$.\n",
        "  * For Example, modal verbs (`MD`) like *will* are very likely to be followed by a verb in the base form, a `VB`, like *race*, therefore it is more likely that modal verbs will occur with main verb.\n",
        "  * We compute the maximum likelihood estimate of this transition probability by counting, out of the times we see the first tag in a labeled corpus, how often the first tag is followed by the second:\n",
        "  $$\n",
        "  \\begin{equation}\n",
        "  P(t_{i} | t_{i-1}) = \\frac{C(t_{i-1}, t_{i})}{C(t_{i-1})} \\\\\n",
        "  P(MD | VB) = \\frac{C(MD, VB)}{C(MD)}\n",
        "  \\end{equation}\n",
        "  $$\n",
        "\n",
        "*   **Emission Probabilities** represents the probability, given a tag that it will be associated with a given word i.e. $P(w_i|t_i)$.\n",
        "  * For Example, probability of a given tag `MD` associated with the word *will* is:\n",
        "  $$\n",
        "  \\begin{equation}\n",
        "  P(w_i|t_i) = \\frac{C(t_i, w_i)}{C(t_i)} \\\\\n",
        "  P(will|MD) = \\frac{C(MD, \\text{will})}{C(MD)}\n",
        "  \\end{equation}\n",
        "  $$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hLzHeEJBb8F"
      },
      "source": [
        "## Exercise 4: \n",
        "\n",
        "Consider that we have an HMM with hidden states Noun, Verb, Adj and the following transition probability where $p(Y_{i+1}|Y_i)$ is the probability of state $Y_{i+1}$ occuring after $Y_i$ and the table of probabilities is as follows:\n",
        "\n",
        "| $p(Y_{i+1}|Y_i)$ | $Y_{i+1}$=Start | $Y_{i+1}$=Noun | $Y_{i+1}$=Verb | $Y_{i+1}$=Adj |\n",
        "|:-----------------|:-----------------|:--------------:|:--------------:|:-------------:|\n",
        "| $Y_i$=Start      | 0.0      |  0.5           |  0.4           | 0.1           |\n",
        "| $Y_i$=Noun       | 0.0       |  0.3           |  0.5           | 0.2           |\n",
        "| $Y_i$=Verb       | 0.0       |  0.7           |  0.2           | 0.1           |\n",
        "| $Y_i$=Adj        | 0.0        |  0.8           |  0.1           | 0.1           |\n",
        "\n",
        "Furthermore, consider that the model has a vocabulary as follows, with the probability of $p(X_i|Y_i)$ as follows \n",
        "\n",
        "| $p(X_i|Y_i)$ | cats | dogs | drink | water | milk | fresh |\n",
        "|:-------------|:----:|:----:|:-----:|:-----:|:----:|:-----:|\n",
        "| $Y_i$=Noun   | 0.2  | 0.2  |  0.2  | 0.2   | 0.1  | 0.0   |\n",
        "| $Y_i$=Verb   | 0.1  | 0.1  | 0.4   | 0.2   | 0.1  | 0.1   |\n",
        "| $Y_i$=Adj    | 0.0  | 0.0  | 0.2   | 0.0   | 0.2  | 0.8   |\n",
        "\n",
        "\n",
        "Implement the above table and write a function that takes a sequence of words and a sequence of part-of-speech tags and returns the probability using the above model. Calculate the probability of the sentence \"*cats drink fresh milk*\" given the tags \"*noun verb adj verb*\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RZV0xS7BiVB"
      },
      "source": [
        "all_tags = [\"start\",\"noun\",\"verb\",\"adj\"]\n",
        "all_words = [\"cats\",\"dogs\",\"drink\",\"water\",\"milk\",\"fresh\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM5PV12GULWT"
      },
      "source": [
        "transitions = {\n",
        "  'start': {'noun': 0.5, 'verb': 0.4, 'adj': 0.1, 'start': 0.0},\n",
        "  'noun': {'noun': 0.3, 'verb': 0.5, 'adj': 0.2, 'start': 0.0},\n",
        "  'verb': {'noun': 0.7, 'verb': 0.2, 'adj': 0.1, 'start': 0.0},\n",
        "  'adj': {'noun': 0.8, 'verb': 0.1, 'adj': 0.1, 'start': 0.0},\n",
        "}\n",
        "\n",
        "emissions = {\n",
        "  'noun': {'cats': 0.2, 'dogs': 0.2, 'drink': 0.2, 'fresh': 0.0, 'milk': 0.1, 'water': 0.2},\n",
        "  'verb': {'cats': 0.1, 'dogs': 0.1, 'drink': 0.4, 'fresh': 0.1, 'milk': 0.1, 'water': 0.2},\n",
        "  'adj': {'cats': 0.0, 'dogs': 0.0, 'drink': 0.2, 'fresh': 0.8, 'milk': 0.2, 'water': 0.0},\n",
        "  'start': {'cats': 0.0, 'dogs': 0.0, 'drink': 0.0, 'fresh': 0.0, 'milk': 0.0, 'water': 0.0},\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_moLAxIRBp7v",
        "outputId": "5c97c6b5-48d4-447c-c871-eca896daf792"
      },
      "source": [
        "def hmm(words, tags):\n",
        "    prob = 1.0\n",
        "    \n",
        "    prev_tag = 'start'   # 'start' is same as t0 in lecture slides\n",
        "\n",
        "    for tag, word in zip(tags, words):\n",
        "      prob = prob * transitions[prev_tag][tag] * emissions[tag][word]\n",
        "      prev_tag = tag\n",
        "\n",
        "    return prob\n",
        "\n",
        "print(hmm([\"cats\",\"drink\",\"fresh\",\"milk\"], [\"noun\",\"verb\",\"adj\",\"verb\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6000000000000006e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIVlRBrNEwbp"
      },
      "source": [
        "## Exercise 5 \n",
        "Write a function that learns the emission and transition probabilities for the Hidden Markov Model using the tagged corpus given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9A6RFCpEu-y"
      },
      "source": [
        "sentences = [\n",
        "    [\"cats\",\"drink\",\"milk\"],\n",
        "    [\"dogs\",\"drink\",\"water\"],\n",
        "    [\"fresh\",\"milk\"],\n",
        "    [\"dogs\",\"drink\",\"fresh\",\"milk\"],\n",
        "    [\"cats\",\"milk\"]\n",
        "]\n",
        "\n",
        "tagged = [\n",
        "    [\"noun\",\"verb\",\"noun\"],\n",
        "    [\"noun\",\"verb\",\"noun\"],\n",
        "    [\"adj\",\"noun\"],\n",
        "    [\"noun\",\"verb\",\"adj\",\"noun\"],\n",
        "    [\"noun\",\"noun\"]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxxjU0_XFBSc",
        "outputId": "c275e0e3-92eb-40bb-f57f-3b2cce812c05"
      },
      "source": [
        "def hmm_learn(sentences, tagged):\n",
        "    # Reserve a dictionary for transition and emission probabilities\n",
        "    transitions = {t:{t2:0.0 for t2 in all_tags} for t in all_tags}\n",
        "    emissions    = {t:{w:0.0 for w in all_words} for t in all_tags}\n",
        "    # Reserve a dictionary for transition and emission counts\n",
        "    transitions_counts = {t:{t2:0.0 for t2 in all_tags} for t in all_tags}\n",
        "    emissions_counts = {t:{w:0.0 for w in all_words} for t in all_tags}\n",
        "\n",
        "    # Iterate through sentence and tag pair\n",
        "    for sents, tags in zip(sentences, tagged):\n",
        "      prev = \"start\"\n",
        "      # Iterated through word and tag pair\n",
        "      for word, tag in zip(sents, tags):\n",
        "        # Update the transitions and emission counts\n",
        "        transitions_counts[prev][tag] += 1\n",
        "        emissions_counts[prev][word] += 1\n",
        "        prev = tag\n",
        "\n",
        "    # Calculate the transitions_counts total and emissions_counts total by adding counts\n",
        "    for tag in all_tags:\n",
        "      transitions_total = sum(transitions_counts[tag].values())\n",
        "      emissions_total = sum(emissions_counts[tag].values())\n",
        "\n",
        "      if transitions_total > 0:  # avoid dividing by zero\n",
        "        # normalize the tag counts\n",
        "        for next_tag in all_tags:\n",
        "          transitions[tag][next_tag] = transitions_counts[tag][next_tag] / transitions_total\n",
        "\n",
        "      if emissions_total > 0:  # avoid dividing by zero\n",
        "        # normalize the word counts\n",
        "        for word in all_words:\n",
        "          emissions[tag][word] = emissions_counts[tag][word] / emissions_total\n",
        "\n",
        "    return transitions, emissions\n",
        "\n",
        "transitions, emissions = hmm_learn(sentences, tagged)\n",
        "\n",
        "import pprint\n",
        "print('Transitions')\n",
        "pprint.pprint(transitions)\n",
        "print('\\n')\n",
        "print('Emissions')\n",
        "pprint.pprint(emissions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transitions\n",
            "{'adj': {'adj': 0.0, 'noun': 1.0, 'start': 0.0, 'verb': 0.0},\n",
            " 'noun': {'adj': 0.0, 'noun': 0.25, 'start': 0.0, 'verb': 0.75},\n",
            " 'start': {'adj': 0.2, 'noun': 0.8, 'start': 0.0, 'verb': 0.0},\n",
            " 'verb': {'adj': 0.3333333333333333,\n",
            "          'noun': 0.6666666666666666,\n",
            "          'start': 0.0,\n",
            "          'verb': 0.0}}\n",
            "\n",
            "\n",
            "Emissions\n",
            "{'adj': {'cats': 0.0,\n",
            "         'dogs': 0.0,\n",
            "         'drink': 0.0,\n",
            "         'fresh': 1.0,\n",
            "         'milk': 0.0,\n",
            "         'water': 0.0},\n",
            " 'noun': {'cats': 0.2222222222222222,\n",
            "          'dogs': 0.2222222222222222,\n",
            "          'drink': 0.0,\n",
            "          'fresh': 0.0,\n",
            "          'milk': 0.4444444444444444,\n",
            "          'water': 0.1111111111111111},\n",
            " 'start': {'cats': 0.0,\n",
            "           'dogs': 0.0,\n",
            "           'drink': 0.0,\n",
            "           'fresh': 0.0,\n",
            "           'milk': 0.0,\n",
            "           'water': 0.0},\n",
            " 'verb': {'cats': 0.0,\n",
            "          'dogs': 0.0,\n",
            "          'drink': 1.0,\n",
            "          'fresh': 0.0,\n",
            "          'milk': 0.0,\n",
            "          'water': 0.0}}\n"
          ]
        }
      ]
    }
  ]
}